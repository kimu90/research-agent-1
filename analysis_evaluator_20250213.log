2025-02-13 07:09:27 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:09:29 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:09:29 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:09:29 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:09:29 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:09:29 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:29 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:09:30 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:09:30 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 07:09:36 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:37 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:09:38 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:38 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:09:38 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:38 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:09:38 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:38 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:38 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:09:38 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:09:38 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:09:38 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:09:38 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:09:38 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:09:38 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:09:38 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:09:38 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:09:38 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:09:38 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:09:39 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:09:39 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:09:39 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:09:39 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:09:39 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:16:21 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:22 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:16:22 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:23 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:16:23 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:23 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:16:23 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:23 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:23 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:16:23 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:16:23 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:16:23 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:16:24 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:16:24 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:16:24 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:16:24 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:16:24 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:16:24 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:16:24 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:16:24 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:16:24 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:16:24 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:16:24 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:16:24 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 07:25:42 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:25:44 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:25:44 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:25:44 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:25:44 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:25:44 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:44 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:25:44 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:25:44 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 07:25:52 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:53 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:25:53 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:53 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:25:53 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:53 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:25:53 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:54 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:54 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:25:54 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:25:54 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:25:54 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:25:54 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:25:54 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:25:54 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:25:54 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:25:54 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:25:54 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:25:54 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:25:54 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:25:54 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:25:54 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:25:54 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:25:54 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 07:31:14 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 07:31:14 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 07:31:14 - controllers.analyze_data_router - INFO - Fetching available datasets
2025-02-13 07:31:14 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:31:14 - controllers.analyze_data_router - DEBUG - AnalysisAgent initialized
2025-02-13 07:31:14 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:31:14 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:31:14 - controllers.analyze_data_router - INFO - Successfully retrieved 5 datasets
2025-02-13 07:31:14 - controllers.analyze_data_router - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:31:42 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:31:42 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 07:31:42 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:31:42 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:31:42 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:31:42 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:31:42 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:31:42 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 07:31:42 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 07:31:42 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:31:42 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:31:42 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:31:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:31:42 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:31:42 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725528638450>
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:31:42 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:31:42 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:31:43 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 07:31:43 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 07:31:44 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15377
2025-02-13 07:31:44 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 07:31:45 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 07:31:45 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 07:31:47 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 07:31:47 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 07:31:47 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 07:31:47 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:31:48 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 07:31:48 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:31:48 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 07:31:49 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=481f5f53-3613-40b3-953c-94de39b7f514 HTTP/1.1" 302 0
2025-02-13 07:31:49 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 07:31:50 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 07:31:50 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 07:31:50 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 07:31:50 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 07:31:50 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7255282b4a90>
2025-02-13 07:31:50 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x725552a41250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 07:31:50 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725511fc29d0>
2025-02-13 07:31:50 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:31:50 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:31:50 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:31:50 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:31:50 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 07:31:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz3h78bf85ar404p8qta8db'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4SIbk3fDoFAblkKMVmWpF.Mdeaw9qT4dja2_2jsbcRs-1739431912-1.0.1.1-P.rX5WpcgNk1M720EOdotYmT2ciSuXr48ez_MZhvPxfWt2qLn7TmsXWe9_nZZ6_826obs0Ij5IIwf8lnupVuaQ; path=/; expires=Thu, 13-Feb-25 08:01:52 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91131f00ce4f80b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:31:52 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 07:31:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz3h78bf85ar404p8qta8db', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=4SIbk3fDoFAblkKMVmWpF.Mdeaw9qT4dja2_2jsbcRs-1739431912-1.0.1.1-P.rX5WpcgNk1M720EOdotYmT2ciSuXr48ez_MZhvPxfWt2qLn7TmsXWe9_nZZ6_826obs0Ij5IIwf8lnupVuaQ; path=/; expires=Thu, 13-Feb-25 08:01:52 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91131f00ce4f80b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 07:31:52 - root - INFO - Inference completed in 2.59s
2025-02-13 07:31:52 - root - INFO - Tokens used - Input: 320, Output: 651, Total: 971
2025-02-13 07:31:52 - root - INFO - Processing speed - 374.19 tokens/second
2025-02-13 07:31:52 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3308
2025-02-13 07:31:52 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 07:31:52 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 07:31:52 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.487107, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:31:52.834562'}
2025-02-13 07:31:52 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.487107, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:31:52.834562'}
2025-02-13 07:31:52 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 07:31:52 - httpcore.connection - DEBUG - close.started
2025-02-13 07:31:52 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:31:52 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:31:52 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725511fc3850>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:31:52 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:31:52 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:31:52 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 07:31:52 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3302
2025-02-13 07:31:52 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 07:31:52 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 651, 'total_tokens': 971, 'model': 'llama3-70b-8192'}
2025-02-13 07:33:18 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:33:18 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'sea weed', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 07:33:18 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:33:18 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:33:18 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - - Query: sea weed
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:33:18 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:33:18 - httpcore.connection - DEBUG - close.started
2025-02-13 07:33:18 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:33:18 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:33:18 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:33:18 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x72552b6fbad0>
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:33:18 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea weed
2025-02-13 07:33:18 - tools.research.analysis_agent - INFO - Starting analysis for query: sea weed
2025-02-13 07:33:18 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:33:18 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:33:18 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:33:18 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:33:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:33:18 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:33:19 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:33:19 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:33:19 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+weed+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2938
2025-02-13 07:33:19 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 07:33:21 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/environmental-archaeology/articles/10.3389/fearc.2024.1465082/full HTTP/1.1" 200 None
2025-02-13 07:33:21 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:33:23 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 303 150
2025-02-13 07:33:23 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:33:24 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7 HTTP/1.1" 302 0
2025-02-13 07:33:24 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7&code=2428c3d0-67f6-44be-bded-6ec3fb78950f HTTP/1.1" 302 0
2025-02-13 07:33:25 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 200 None
2025-02-13 07:33:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 07:33:26 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0960852424013531 HTTP/1.1" 403 None
2025-02-13 07:33:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 07:33:26 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/354281748_Characterizing_energy_flow_in_kelp_forest_food_webs_a_geochemical_review_and_call_for_additional_research HTTP/1.1" 403 None
2025-02-13 07:33:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:33:27 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 303 150
2025-02-13 07:33:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:33:28 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y HTTP/1.1" 302 0
2025-02-13 07:33:28 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y&code=f76cc58c-fdbb-4284-9bc0-772c1613274d HTTP/1.1" 302 0
2025-02-13 07:33:29 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 200 None
2025-02-13 07:33:29 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 07:33:29 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea weed.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 07:33:29 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 07:33:29 - httpcore.connection - DEBUG - close.started
2025-02-13 07:33:29 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:33:29 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 07:33:30 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x72552835a910>
2025-02-13 07:33:30 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x725552a41250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 07:33:30 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725528322fd0>
2025-02-13 07:33:30 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:33:30 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:33:30 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:33:30 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:33:30 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 07:33:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jkz3m8fke4atwm1ean98xxw9'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9113216f1ac93c34-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:33:32 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 07:33:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jkz3m8fke4atwm1ean98xxw9', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '9113216f1ac93c34-BOM', 'content-encoding': 'gzip'})
2025-02-13 07:33:32 - root - INFO - Inference completed in 2.40s
2025-02-13 07:33:32 - root - INFO - Tokens used - Input: 315, Output: 619, Total: 934
2025-02-13 07:33:32 - root - INFO - Processing speed - 389.20 tokens/second
2025-02-13 07:33:32 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3073
2025-02-13 07:33:32 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 07:33:32 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 07:33:32 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 13.414852, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:33:32.308031'}
2025-02-13 07:33:32 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 13.414852, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:33:32.308031'}
2025-02-13 07:33:32 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 07:33:32 - httpcore.connection - DEBUG - close.started
2025-02-13 07:33:32 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:33:32 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:33:32 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725511fdbad0>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:33:32 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:33:32 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:33:32 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 07:33:32 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3066
2025-02-13 07:33:32 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 07:33:32 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 635, 'completion_tokens': 1270, 'total_tokens': 1905, 'model': 'llama3-70b-8192'}
2025-02-13 07:44:13 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:44:13 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Rhizophora spp', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 07:44:13 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:44:13 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:44:13 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - - Query: Rhizophora spp
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:44:13 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:44:13 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:44:13 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Rhizophora spp
2025-02-13 07:44:13 - tools.research.analysis_agent - INFO - Starting analysis for query: Rhizophora spp
2025-02-13 07:44:13 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:44:13 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:44:13 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:44:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:44:13 - httpcore.connection - DEBUG - close.started
2025-02-13 07:44:13 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:44:13 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:44:13 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x725511209290>
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:44:13 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:44:13 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:44:14 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Rhizophora+spp+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 161
2025-02-13 07:44:14 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 07:44:14 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Rhizophora spp.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 07:44:14 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 07:44:14 - httpcore.connection - DEBUG - close.started
2025-02-13 07:44:14 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:44:14 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 07:44:14 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x72551120a950>
2025-02-13 07:44:14 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x725552a41250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 07:44:14 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x72551120a990>
2025-02-13 07:44:14 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:44:14 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:44:14 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:44:14 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:44:14 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 07:44:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5560'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.4s'), (b'x-request-id', b'req_01jkz47xzpeyb9yzhxyq1as34t'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9113312b6ea029f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:44:17 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 07:44:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5560', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.4s', 'x-request-id': 'req_01jkz47xzpeyb9yzhxyq1as34t', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '9113312b6ea029f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 07:44:17 - root - INFO - Inference completed in 2.86s
2025-02-13 07:44:17 - root - INFO - Tokens used - Input: 317, Output: 699, Total: 1016
2025-02-13 07:44:17 - root - INFO - Processing speed - 355.58 tokens/second
2025-02-13 07:44:17 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3180
2025-02-13 07:44:17 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 07:44:17 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 07:44:17 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 3.632659, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:44:17.151424'}
2025-02-13 07:44:17 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 3.632659, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:44:17.151424'}
2025-02-13 07:44:17 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 07:44:17 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:44:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:44:17 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 07:44:17 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3173
2025-02-13 07:44:17 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 07:44:17 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 952, 'completion_tokens': 1969, 'total_tokens': 2921, 'model': 'llama3-70b-8192'}
2025-02-13 07:46:25 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:46:27 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:46:27 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:46:27 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:46:27 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:46:27 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:27 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:46:28 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:46:28 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 07:46:34 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:46:35 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:46:35 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:46:35 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:46:35 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:46:35 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:46:35 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:46:36 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:46:36 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:46:36 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:46:36 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:46:36 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:46:36 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:46:36 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:46:36 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:46:36 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:46:36 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:46:36 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:46:36 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 07:49:18 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 07:49:18 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 07:49:18 - controllers.analyze_data_router - INFO - Fetching available datasets
2025-02-13 07:49:18 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:49:18 - controllers.analyze_data_router - DEBUG - AnalysisAgent initialized
2025-02-13 07:49:18 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:49:18 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:49:18 - controllers.analyze_data_router - INFO - Successfully retrieved 5 datasets
2025-02-13 07:49:18 - controllers.analyze_data_router - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:49:31 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:49:31 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 07:49:31 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:49:31 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:49:31 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:49:31 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:49:31 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:49:31 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 07:49:31 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 07:49:31 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:49:31 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:49:31 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:49:31 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:49:31 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:49:31 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7e01063bca90>
2025-02-13 07:49:31 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:49:31 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:49:31 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:49:31 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:49:31 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:49:31 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 07:49:32 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 07:49:32 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"nc9m8hmbv241"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 07:49:32 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:49:32 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:49:32 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:49:32 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:49:32 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:49:33 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15363
2025-02-13 07:49:33 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 07:49:34 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 07:49:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 07:49:35 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 07:49:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 07:49:35 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 07:49:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:49:36 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 07:49:36 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:49:36 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 07:49:37 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=dff36e86-4193-4d78-920f-227862505641 HTTP/1.1" 302 0
2025-02-13 07:49:37 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 07:49:38 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 07:49:38 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 07:49:38 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 07:49:38 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 07:49:38 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7e00f4aa1b50>
2025-02-13 07:49:38 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7e012d4f92e0> server_hostname='api.groq.com' timeout=5.0
2025-02-13 07:49:38 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7e00f4aa1c10>
2025-02-13 07:49:38 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:49:38 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:49:38 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:49:38 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:49:38 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 07:49:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz4ht4ffba8wh2k9eh1x187'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ii8zpg4nlyEUS7XSAhJkG1QoOgQiF.C7k4O6LPbpqZg-1739432981-1.0.1.1-Ybzz9zPk9XxoendPXF80L3smqEWwRP5Yj8vNKSxPYGbEDgxRUh2ImxpKxDM7Y_qkFGGyItxizwc0X7BVtTdCuQ; path=/; expires=Thu, 13-Feb-25 08:19:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91133913386f80b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:49:41 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 07:49:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz4ht4ffba8wh2k9eh1x187', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Ii8zpg4nlyEUS7XSAhJkG1QoOgQiF.C7k4O6LPbpqZg-1739432981-1.0.1.1-Ybzz9zPk9XxoendPXF80L3smqEWwRP5Yj8vNKSxPYGbEDgxRUh2ImxpKxDM7Y_qkFGGyItxizwc0X7BVtTdCuQ; path=/; expires=Thu, 13-Feb-25 08:19:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91133913386f80b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 07:49:41 - root - INFO - Inference completed in 2.74s
2025-02-13 07:49:41 - root - INFO - Tokens used - Input: 320, Output: 802, Total: 1122
2025-02-13 07:49:41 - root - INFO - Processing speed - 409.26 tokens/second
2025-02-13 07:49:41 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3716
2025-02-13 07:49:41 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 07:49:41 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 07:49:41 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.088557, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:49:41.115567'}
2025-02-13 07:49:41 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.088557, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T07:49:41.115567'}
2025-02-13 07:49:41 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 07:49:41 - httpcore.connection - DEBUG - close.started
2025-02-13 07:49:41 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:49:41 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:49:41 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7e00f4aa3b10>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"vdk84z0qmf41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 07:49:41 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:49:41 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:49:41 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 07:49:41 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3709
2025-02-13 07:49:41 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 07:49:41 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 802, 'total_tokens': 1122, 'model': 'llama3-70b-8192'}
2025-02-13 07:54:28 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:54:29 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:54:29 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:54:29 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:54:29 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:54:29 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:54:29 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:54:30 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:54:30 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:54:30 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:54:30 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:54:30 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:54:30 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:54:30 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:54:30 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:54:30 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:54:30 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:54:30 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:54:30 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 07:55:50 - fastapi - WARNING - email-validator not installed, email fields will be treated as str.
To install, run: pip install email-validator
2025-02-13 07:56:56 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 07:56:57 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 07:56:57 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 07:56:57 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 07:56:57 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 07:56:57 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 07:56:57 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 07:56:58 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 07:56:58 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 07:56:58 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:56:58 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:56:58 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:56:58 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:56:58 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 07:56:58 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 07:56:58 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 07:56:58 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 07:56:58 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 07:56:58 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 07:56:59 - fastapi - WARNING - email-validator not installed, email fields will be treated as str.
To install, run: pip install email-validator
2025-02-13 07:57:42 - controllers.datasets_router - INFO - Attempting to list datasets in: /app/data
2025-02-13 07:57:42 - controllers.datasets_router - INFO - Found 5 datasets
2025-02-13 07:57:42 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 07:57:42 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 07:59:24 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:59:24 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'sea weed', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'research.txt', 'analysis_type': 'general'}
2025-02-13 07:59:24 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:59:24 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:59:24 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - - Query: sea weed
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - - Prompt name: research.txt
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:59:24 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:59:24 - tools.research.analysis_agent - ERROR - Prompt file not found: research.txt
2025-02-13 07:59:24 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:59:24 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea weed
2025-02-13 07:59:24 - tools.research.analysis_agent - INFO - Starting analysis for query: sea weed
2025-02-13 07:59:24 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:59:24 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:59:24 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:59:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:59:24 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:59:24 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da7b1de90>
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"ufp97p7kyw41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 07:59:24 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:59:24 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:59:25 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+weed+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2938
2025-02-13 07:59:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 07:59:26 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/environmental-archaeology/articles/10.3389/fearc.2024.1465082/full HTTP/1.1" 200 None
2025-02-13 07:59:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:59:27 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 303 150
2025-02-13 07:59:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:59:28 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7 HTTP/1.1" 302 0
2025-02-13 07:59:28 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7&code=74c68e12-961a-4fb1-a3e2-723554ab2a7f HTTP/1.1" 302 0
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 200 None
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0960852424013531 HTTP/1.1" 403 None
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/354281748_Characterizing_energy_flow_in_kelp_forest_food_webs_a_geochemical_review_and_call_for_additional_research HTTP/1.1" 403 None
2025-02-13 07:59:29 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 07:59:30 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 303 150
2025-02-13 07:59:30 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 07:59:31 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y HTTP/1.1" 302 0
2025-02-13 07:59:31 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y&code=1e38df44-ac05-459f-ace7-d6fe5fba260a HTTP/1.1" 302 0
2025-02-13 07:59:32 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 200 None
2025-02-13 07:59:32 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 07:59:32 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Analyze the following content and provide a comprehensive summary.\n                \n                Research Topic: {{research_topic}}\n                Content: {{content}}\n                \n                Provide key insights, main themes, and relevant conclusions.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea weed.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 07:59:32 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 07:59:32 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 07:59:32 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85b512d0>
2025-02-13 07:59:32 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 07:59:32 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d86603fd0>
2025-02-13 07:59:32 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:59:32 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:59:32 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:59:32 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:59:32 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:59:34 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 07:59:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5857'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.43s'), (b'x-request-id', b'req_01jkz53y86f4j9a3fb4f626yfe'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CNSsqkgKSOAcRT0kcGQzW_MN.JMy.JZfAFYFNfKLRsM-1739433574-1.0.1.1-JgTUz0BkSurPhVLjrTcMJwwaR9UCaysTTERuSl.5Eslh6hV_Q6vCyOZpNl9WllBDqQnoLH3OpQ4mDFA4lzJz6w; path=/; expires=Thu, 13-Feb-25 08:29:34 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91134793eb1d80b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 07:59:34 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:59:34 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:59:34 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:59:34 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:59:34 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 07:59:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5857', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.43s', 'x-request-id': 'req_01jkz53y86f4j9a3fb4f626yfe', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=CNSsqkgKSOAcRT0kcGQzW_MN.JMy.JZfAFYFNfKLRsM-1739433574-1.0.1.1-JgTUz0BkSurPhVLjrTcMJwwaR9UCaysTTERuSl.5Eslh6hV_Q6vCyOZpNl9WllBDqQnoLH3OpQ4mDFA4lzJz6w; path=/; expires=Thu, 13-Feb-25 08:29:34 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91134793eb1d80b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 07:59:34 - root - INFO - Inference completed in 2.17s
2025-02-13 07:59:34 - root - INFO - Tokens used - Input: 97, Output: 627, Total: 724
2025-02-13 07:59:34 - root - INFO - Processing speed - 333.03 tokens/second
2025-02-13 07:59:34 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3330
2025-02-13 07:59:34 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 07:59:34 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 07:59:34 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 9.912411, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'research.txt', 'timestamp': '2025-02-13T07:59:34.572148'}
2025-02-13 07:59:34 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 9.912411, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'research.txt', 'timestamp': '2025-02-13T07:59:34.572148'}
2025-02-13 07:59:34 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 07:59:35 - httpcore.connection - DEBUG - close.started
2025-02-13 07:59:35 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:59:35 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:59:35 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85b508d0>
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"10pn5cv89qb41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 07:59:35 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:59:35 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:59:35 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 07:59:35 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3245
2025-02-13 07:59:35 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 07:59:35 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 97, 'completion_tokens': 627, 'total_tokens': 724, 'model': 'llama3-70b-8192'}
2025-02-13 07:59:58 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 07:59:58 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 07:59:58 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 07:59:58 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 07:59:58 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 07:59:58 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 07:59:58 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 07:59:58 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 07:59:58 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 07:59:58 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 07:59:58 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 07:59:58 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 07:59:58 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 07:59:59 - httpcore.connection - DEBUG - close.started
2025-02-13 07:59:59 - httpcore.connection - DEBUG - close.complete
2025-02-13 07:59:59 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 07:59:59 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85b3c050>
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"jze4mya5xj41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 07:59:59 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 07:59:59 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 07:59:59 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 07:59:59 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 08:00:01 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15373
2025-02-13 08:00:01 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 08:00:01 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 08:00:01 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 08:00:02 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 08:00:03 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 08:00:03 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 08:00:03 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:00:03 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 08:00:03 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:00:04 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 08:00:04 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=e3b22bee-443a-4421-ab93-83e9db1b57f1 HTTP/1.1" 302 0
2025-02-13 08:00:05 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 08:00:05 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:00:05 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:00:05 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:00:05 - httpcore.connection - DEBUG - close.started
2025-02-13 08:00:05 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:00:05 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:00:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d86673a10>
2025-02-13 08:00:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:00:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da40a3e50>
2025-02-13 08:00:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:00:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:00:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:00:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:00:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:00:08 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:00:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz54ym9e7g95rh93va5fm7b'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91134863396246fb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:00:08 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:00:08 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:00:08 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:00:08 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:00:08 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:00:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz54ym9e7g95rh93va5fm7b', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91134863396246fb-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:00:08 - root - INFO - Inference completed in 3.30s
2025-02-13 08:00:08 - root - INFO - Tokens used - Input: 320, Output: 982, Total: 1302
2025-02-13 08:00:08 - root - INFO - Processing speed - 393.97 tokens/second
2025-02-13 08:00:08 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 4166
2025-02-13 08:00:08 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:00:08 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:00:08 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 9.908231, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:00:08.869059'}
2025-02-13 08:00:08 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 9.908231, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:00:08.869059'}
2025-02-13 08:00:08 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:00:09 - httpcore.connection - DEBUG - close.started
2025-02-13 08:00:09 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:00:09 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:00:09 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da40a3ad0>
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"xfw1ysi27841"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:00:09 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:00:09 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:00:09 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:00:09 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 4156
2025-02-13 08:00:09 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:00:09 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 417, 'completion_tokens': 1609, 'total_tokens': 2026, 'model': 'llama3-70b-8192'}
2025-02-13 08:11:06 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:11:06 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'sea cucumber', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:11:06 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:11:06 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:11:06 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - - Query: sea cucumber
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:11:06 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:11:06 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:11:06 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea cucumber
2025-02-13 08:11:06 - tools.research.analysis_agent - INFO - Starting analysis for query: sea cucumber
2025-02-13 08:11:06 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:11:06 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:11:06 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:11:06 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:11:06 - httpcore.connection - DEBUG - close.started
2025-02-13 08:11:06 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:11:06 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:11:06 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d86601a10>
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"5emvvohs4l41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:11:06 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:11:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:11:07 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+cucumber+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2934
2025-02-13 08:11:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 08:11:07 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0048969724059485 HTTP/1.1" 403 None
2025-02-13 08:11:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:11:08 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.917857/full HTTP/1.1" 200 None
2025-02-13 08:11:09 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:11:10 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.931903/full HTTP/1.1" 200 None
2025-02-13 08:11:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:11:11 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 303 150
2025-02-13 08:11:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:11:12 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0 HTTP/1.1" 302 0
2025-02-13 08:11:12 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0&code=5e73b279-f2e7-486e-8bd2-97fd25400abc HTTP/1.1" 302 0
2025-02-13 08:11:13 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 200 None
2025-02-13 08:11:14 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 08:11:14 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/abs/pii/S0013935124006522 HTTP/1.1" 403 None
2025-02-13 08:11:14 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:11:14 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea cucumber.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:11:14 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:11:14 - httpcore.connection - DEBUG - close.started
2025-02-13 08:11:14 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:11:14 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:11:14 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d866725d0>
2025-02-13 08:11:14 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:11:14 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d8503a090>
2025-02-13 08:11:14 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:11:14 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:11:14 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:11:14 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:11:14 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:11:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5561'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.39s'), (b'x-request-id', b'req_01jkz5sbvaefpa5xhkfyq68mmp'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911358b7cb8680b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:11:17 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:11:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5561', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.39s', 'x-request-id': 'req_01jkz5sbvaefpa5xhkfyq68mmp', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '911358b7cb8680b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:11:17 - root - INFO - Inference completed in 2.57s
2025-02-13 08:11:17 - root - INFO - Tokens used - Input: 315, Output: 741, Total: 1056
2025-02-13 08:11:17 - root - INFO - Processing speed - 410.56 tokens/second
2025-02-13 08:11:17 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3644
2025-02-13 08:11:17 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:11:17 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:11:17 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.794979, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:11:17.015496'}
2025-02-13 08:11:17 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.794979, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:11:17.015496'}
2025-02-13 08:11:17 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:11:17 - httpcore.connection - DEBUG - close.started
2025-02-13 08:11:17 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:11:17 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:11:17 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d86670790>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"eginmly1g41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:11:17 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:11:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:11:17 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:11:17 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3632
2025-02-13 08:11:17 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:11:17 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 732, 'completion_tokens': 2350, 'total_tokens': 3082, 'model': 'llama3-70b-8192'}
2025-02-13 08:24:38 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:24:38 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:24:38 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:24:38 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:24:38 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:24:38 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:24:38 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:24:38 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 08:24:38 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 08:24:38 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:24:38 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:24:38 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:24:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:24:38 - httpcore.connection - DEBUG - close.started
2025-02-13 08:24:38 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:24:38 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:24:38 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84c0f990>
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"14p8lrbxvon41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:24:38 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:24:38 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:24:38 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 08:24:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 08:24:40 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15370
2025-02-13 08:24:40 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 08:24:40 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 08:24:40 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 08:24:42 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 08:24:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 08:24:42 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 08:24:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:24:43 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 08:24:43 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:24:43 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 08:24:43 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=c324c9ba-8284-4130-bc1c-6a516de2b6a4 HTTP/1.1" 302 0
2025-02-13 08:24:44 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 08:24:44 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:24:44 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:24:44 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:24:44 - httpcore.connection - DEBUG - close.started
2025-02-13 08:24:44 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:24:44 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:24:44 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a4ab90>
2025-02-13 08:24:44 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:24:44 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da7dc4a10>
2025-02-13 08:24:44 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:24:44 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:24:44 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:24:44 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:24:44 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:24:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:24:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz6j39aftfrb6qw3c0c4y2e'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2xDWv0C6m2kmj7nOG.oIWFJFYcsg3FUh3oYGVputiEU-1739435088-1.0.1.1-lByE3jdYRIyUmBgQi3Ibfqlofv2NKIkpDltERoKDQyInio4vZdRstZBGi9yXNeW7ytwXpxgWRQLsW7fBBwLxNQ; path=/; expires=Thu, 13-Feb-25 08:54:48 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91136c80fdff29f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:24:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:24:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:24:48 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:24:48 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:24:48 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:24:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz6j39aftfrb6qw3c0c4y2e', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=2xDWv0C6m2kmj7nOG.oIWFJFYcsg3FUh3oYGVputiEU-1739435088-1.0.1.1-lByE3jdYRIyUmBgQi3Ibfqlofv2NKIkpDltERoKDQyInio4vZdRstZBGi9yXNeW7ytwXpxgWRQLsW7fBBwLxNQ; path=/; expires=Thu, 13-Feb-25 08:54:48 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91136c80fdff29f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:24:48 - root - INFO - Inference completed in 3.95s
2025-02-13 08:24:48 - root - INFO - Tokens used - Input: 320, Output: 1143, Total: 1463
2025-02-13 08:24:48 - root - INFO - Processing speed - 369.92 tokens/second
2025-02-13 08:24:48 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 4816
2025-02-13 08:24:48 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:24:48 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:24:48 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.647319, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:24:48.678825'}
2025-02-13 08:24:48 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.647319, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:24:48.678825'}
2025-02-13 08:24:48 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:24:49 - httpcore.connection - DEBUG - close.started
2025-02-13 08:24:49 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:24:49 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:24:49 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a40a50>
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"t1oiviakas41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:24:49 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:24:49 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:24:49 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:24:49 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 4803
2025-02-13 08:24:49 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:24:49 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 1052, 'completion_tokens': 3493, 'total_tokens': 4545, 'model': 'llama3-70b-8192'}
2025-02-13 08:32:48 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:32:48 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Thalassia testudinum', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:32:48 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:32:48 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:32:48 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - - Query: Thalassia testudinum
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:32:48 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:32:48 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:32:48 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Thalassia testudinum
2025-02-13 08:32:48 - tools.research.analysis_agent - INFO - Starting analysis for query: Thalassia testudinum
2025-02-13 08:32:48 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:32:48 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:32:48 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:32:48 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:32:48 - httpcore.connection - DEBUG - close.started
2025-02-13 08:32:48 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:32:48 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:32:48 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d86601c10>
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"17rzxa9rzl841"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:32:48 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:32:48 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:32:49 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Thalassia+testudinum+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 167
2025-02-13 08:32:49 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:32:49 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Thalassia testudinum.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:32:49 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:32:49 - httpcore.connection - DEBUG - close.started
2025-02-13 08:32:49 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:32:49 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:32:49 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a46510>
2025-02-13 08:32:49 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:32:49 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84c0c690>
2025-02-13 08:32:49 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:32:49 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:32:49 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:32:49 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:32:49 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:32:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz70wd5e7ds464dzgn5f6rm'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91137854fee880b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:32:52 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:32:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz70wd5e7ds464dzgn5f6rm', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91137854fee880b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:32:52 - root - INFO - Inference completed in 3.32s
2025-02-13 08:32:52 - root - INFO - Tokens used - Input: 321, Output: 955, Total: 1276
2025-02-13 08:32:52 - root - INFO - Processing speed - 384.85 tokens/second
2025-02-13 08:32:52 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3941
2025-02-13 08:32:52 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:32:52 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:32:52 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 4.211604, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:32:52.498317'}
2025-02-13 08:32:52 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 4.211604, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:32:52.498317'}
2025-02-13 08:32:52 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"u2med1phmn41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:32:52 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:32:52 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:32:52 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:32:52 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3931
2025-02-13 08:32:52 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:32:52 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 1373, 'completion_tokens': 4448, 'total_tokens': 5821, 'model': 'llama3-70b-8192'}
2025-02-13 08:33:27 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:33:27 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'snail', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:33:27 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:33:27 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:33:27 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - - Query: snail
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:33:27 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:33:27 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:33:27 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: snail
2025-02-13 08:33:27 - tools.research.analysis_agent - INFO - Starting analysis for query: snail
2025-02-13 08:33:27 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:33:27 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:33:27 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:33:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:33:27 - httpcore.connection - DEBUG - close.started
2025-02-13 08:33:27 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:33:27 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:33:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d848e70d0>
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"h5ofshyxq641"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:33:27 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:33:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:33:28 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=snail+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 3138
2025-02-13 08:33:28 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:33:29 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06353-y HTTP/1.1" 200 112879
2025-02-13 08:33:29 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:33:30 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/ecology-and-evolution/articles/10.3389/fevo.2024.1329581/full HTTP/1.1" 200 None
2025-02-13 08:33:31 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 08:33:31 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S240584402409100X HTTP/1.1" 403 None
2025-02-13 08:33:31 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.earth.com:443
2025-02-13 08:33:32 - urllib3.connectionpool - DEBUG - https://www.earth.com:443 "GET /news/slugs-and-snails-prefer-los-angeles-city-life-over-rural-areas/ HTTP/1.1" 200 None
2025-02-13 08:33:32 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:33:34 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06298-2 HTTP/1.1" 200 97205
2025-02-13 08:33:34 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:33:34 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: snail.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:33:34 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:33:34 - httpcore.connection - DEBUG - close.started
2025-02-13 08:33:34 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:33:34 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:33:34 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a08850>
2025-02-13 08:33:34 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:33:34 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a08890>
2025-02-13 08:33:34 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:33:34 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:33:34 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:33:34 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:33:34 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:33:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jkz728g7fmttfegcr4qvjxec'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9113796f2ad129f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:33:37 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:33:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jkz728g7fmttfegcr4qvjxec', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '9113796f2ad129f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:33:37 - root - INFO - Inference completed in 3.40s
2025-02-13 08:33:37 - root - INFO - Tokens used - Input: 315, Output: 837, Total: 1152
2025-02-13 08:33:37 - root - INFO - Processing speed - 338.58 tokens/second
2025-02-13 08:33:37 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3832
2025-02-13 08:33:37 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:33:37 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:33:37 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.237258, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:33:37.762110'}
2025-02-13 08:33:37 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.237258, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:33:37.762110'}
2025-02-13 08:33:37 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:33:37 - httpcore.connection - DEBUG - close.started
2025-02-13 08:33:37 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:33:37 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:33:37 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d847fdb50>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"ho4y0vs61e41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:33:37 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:33:37 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:33:37 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:33:37 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3819
2025-02-13 08:33:37 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:33:37 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 1688, 'completion_tokens': 5285, 'total_tokens': 6973, 'model': 'llama3-70b-8192'}
2025-02-13 08:36:27 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:36:27 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:36:27 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:36:27 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:36:27 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:36:27 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:36:27 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:36:27 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 08:36:27 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 08:36:27 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:36:27 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:36:27 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:36:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:36:27 - httpcore.connection - DEBUG - close.started
2025-02-13 08:36:27 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:36:27 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:36:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a20110>
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"r5yv2x304h41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:36:27 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:36:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:36:28 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 08:36:28 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 08:36:38 - tools.research.analysis_agent - WARNING - Error scraping https://www.oilfieldtechnology.com/exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/: HTTPSConnectionPool(host='www.oilfieldtechnology.com', port=443): Max retries exceeded with url: /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x778d84a21d10>, 'Connection to www.oilfieldtechnology.com timed out. (connect timeout=10)'))
2025-02-13 08:36:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 08:36:39 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 08:36:39 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 08:36:40 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 08:36:40 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 08:36:41 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 08:36:41 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:36:41 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 08:36:41 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:36:42 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 08:36:42 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=18c15508-0274-42c2-b7bb-7030a8668dd9 HTTP/1.1" 302 0
2025-02-13 08:36:43 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 08:36:43 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:36:43 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:36:43 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:36:43 - httpcore.connection - DEBUG - close.started
2025-02-13 08:36:43 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:36:43 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:36:43 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85cf5a50>
2025-02-13 08:36:43 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:36:43 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85cf4f90>
2025-02-13 08:36:43 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:36:43 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:36:43 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:36:43 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:36:43 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:36:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:36:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz781gafpdt3zvsxnafzst4'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91137e0f2b123e40-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:36:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:36:46 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:36:46 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:36:46 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:36:46 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:36:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz781gafpdt3zvsxnafzst4', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91137e0f2b123e40-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:36:46 - root - INFO - Inference completed in 3.04s
2025-02-13 08:36:46 - root - INFO - Tokens used - Input: 320, Output: 884, Total: 1204
2025-02-13 08:36:46 - root - INFO - Processing speed - 396.08 tokens/second
2025-02-13 08:36:46 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3765
2025-02-13 08:36:46 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:36:46 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:36:46 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 19.58786, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:36:46.964594'}
2025-02-13 08:36:46 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 19.58786, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:36:46.964594'}
2025-02-13 08:36:46 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:36:47 - httpcore.connection - DEBUG - close.started
2025-02-13 08:36:47 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:36:47 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:36:47 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a0a410>
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"ssti0lbfaf41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:36:47 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:36:47 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:36:47 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:36:47 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3755
2025-02-13 08:36:47 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:36:47 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 2008, 'completion_tokens': 6169, 'total_tokens': 8177, 'model': 'llama3-70b-8192'}
2025-02-13 08:37:24 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:37:24 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'snail', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:37:24 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:37:24 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:37:24 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - - Query: snail
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:37:24 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:37:24 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:37:24 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: snail
2025-02-13 08:37:24 - tools.research.analysis_agent - INFO - Starting analysis for query: snail
2025-02-13 08:37:24 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:37:24 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:37:24 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:37:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:37:24 - httpcore.connection - DEBUG - close.started
2025-02-13 08:37:24 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:37:24 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:37:24 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85093110>
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"5n05hll2uw41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:37:24 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:37:24 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:37:24 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=snail+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 3138
2025-02-13 08:37:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:37:25 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06353-y HTTP/1.1" 200 112879
2025-02-13 08:37:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:37:26 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/ecology-and-evolution/articles/10.3389/fevo.2024.1329581/full HTTP/1.1" 200 None
2025-02-13 08:37:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 08:37:27 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S240584402409100X HTTP/1.1" 403 None
2025-02-13 08:37:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.earth.com:443
2025-02-13 08:37:27 - urllib3.connectionpool - DEBUG - https://www.earth.com:443 "GET /news/slugs-and-snails-prefer-los-angeles-city-life-over-rural-areas/ HTTP/1.1" 200 None
2025-02-13 08:37:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:37:27 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06298-2 HTTP/1.1" 200 97205
2025-02-13 08:37:27 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:37:27 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: snail.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:37:27 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:37:27 - httpcore.connection - DEBUG - close.started
2025-02-13 08:37:27 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:37:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:37:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84fb56d0>
2025-02-13 08:37:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:37:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84fb5950>
2025-02-13 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:37:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:37:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:37:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:37:30 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:37:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jkz79cc0fcga80dktp1kb1sn'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91137f218c7229f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:37:30 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:37:30 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:37:30 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:37:30 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:37:30 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:37:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jkz79cc0fcga80dktp1kb1sn', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91137f218c7229f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:37:30 - root - INFO - Inference completed in 2.86s
2025-02-13 08:37:30 - root - INFO - Tokens used - Input: 315, Output: 837, Total: 1152
2025-02-13 08:37:30 - root - INFO - Processing speed - 403.50 tokens/second
2025-02-13 08:37:30 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 4045
2025-02-13 08:37:30 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:37:30 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:37:30 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 6.61594, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:37:30.679774'}
2025-02-13 08:37:30 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 6.61594, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:37:30.679774'}
2025-02-13 08:37:30 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:37:31 - httpcore.connection - DEBUG - close.started
2025-02-13 08:37:31 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:37:31 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:37:31 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a41c10>
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"12qstdjrjq41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:37:31 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:37:31 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:37:31 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:37:31 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 4033
2025-02-13 08:37:31 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:37:31 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 2323, 'completion_tokens': 7006, 'total_tokens': 9329, 'model': 'llama3-70b-8192'}
2025-02-13 08:38:02 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:38:02 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'kangaroo', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:38:02 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:38:02 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:38:02 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - - Query: kangaroo
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:38:02 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:38:02 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:38:02 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: kangaroo
2025-02-13 08:38:02 - tools.research.analysis_agent - INFO - Starting analysis for query: kangaroo
2025-02-13 08:38:02 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:38:02 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:38:02 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:38:02 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:38:03 - httpcore.connection - DEBUG - close.started
2025-02-13 08:38:03 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:38:03 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:38:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d84a0b390>
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"q4zxxfijoz41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:38:03 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:38:03 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:38:03 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=kangaroo+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2765
2025-02-13 08:38:03 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.eurekalert.org:443
2025-02-13 08:38:05 - urllib3.connectionpool - DEBUG - https://www.eurekalert.org:443 "GET /news-releases/1069952 HTTP/1.1" 200 None
2025-02-13 08:38:05 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.scimex.org:443
2025-02-13 08:38:07 - urllib3.connectionpool - DEBUG - https://www.scimex.org:443 "GET /newsfeed/a-varied-diet-was-likely-the-spice-of-life-for-early-kangaroos HTTP/1.1" 200 None
2025-02-13 08:38:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:38:09 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/pediatrics/articles/10.3389/fped.2023.1098143/full HTTP/1.1" 200 None
2025-02-13 08:38:09 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.science.org:443
2025-02-13 08:38:10 - urllib3.connectionpool - DEBUG - https://www.science.org:443 "GET /content/article/kangaroo-research-wins-dance-phd-contest HTTP/1.1" 403 None
2025-02-13 08:38:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): phys.org:443
2025-02-13 08:38:11 - urllib3.connectionpool - DEBUG - https://phys.org:443 "GET /news/2024-06-high-tech-kangaroo-collars-aim.html HTTP/1.1" 200 None
2025-02-13 08:38:11 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:38:11 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: kangaroo.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:38:11 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:38:11 - httpcore.connection - DEBUG - close.started
2025-02-13 08:38:11 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:38:11 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:38:11 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da42476d0>
2025-02-13 08:38:11 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x778dcee29250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:38:11 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778da4245450>
2025-02-13 08:38:11 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:38:11 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:38:11 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:38:11 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:38:11 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:38:13 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:38:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jkz7aq4we0k9n3wr88mexrd0'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911380333bad80b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:38:13 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:38:13 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:38:13 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:38:13 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:38:13 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:38:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jkz7aq4we0k9n3wr88mexrd0', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '911380333bad80b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:38:13 - root - INFO - Inference completed in 2.10s
2025-02-13 08:38:13 - root - INFO - Tokens used - Input: 315, Output: 599, Total: 914
2025-02-13 08:38:13 - root - INFO - Processing speed - 436.24 tokens/second
2025-02-13 08:38:13 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3238
2025-02-13 08:38:13 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:38:13 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:38:13 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 11.070976, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:38:13.718498'}
2025-02-13 08:38:13 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 11.070976, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:38:13.718498'}
2025-02-13 08:38:13 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:38:14 - httpcore.connection - DEBUG - close.started
2025-02-13 08:38:14 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:38:14 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:38:14 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x778d85cf5a90>
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"uly40q0sg41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:38:14 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:38:14 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:38:14 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:38:14 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3231
2025-02-13 08:38:14 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:38:14 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 2638, 'completion_tokens': 7605, 'total_tokens': 10243, 'model': 'llama3-70b-8192'}
2025-02-13 08:42:18 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:19 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:42:19 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:19 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:42:19 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:19 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:42:19 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:20 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:20 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:42:20 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:42:20 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:42:20 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:42:20 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:42:20 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 08:42:20 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:42:20 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:42:20 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:42:20 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:42:20 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:42:20 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:42:20 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:42:20 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:42:20 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:42:20 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 08:42:23 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:42:23 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:42:23 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:42:23 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:42:23 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:42:23 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:42:23 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:42:23 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 08:42:23 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 08:42:23 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:42:23 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:42:23 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:42:23 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:42:24 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:42:24 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f60050ed50>
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"vgw0ky5png41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:42:24 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:42:24 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:42:24 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 08:42:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 08:42:35 - tools.research.analysis_agent - WARNING - Error scraping https://www.oilfieldtechnology.com/exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/: HTTPSConnectionPool(host='www.oilfieldtechnology.com', port=443): Max retries exceeded with url: /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x74f6005197d0>, 'Connection to www.oilfieldtechnology.com timed out. (connect timeout=10)'))
2025-02-13 08:42:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 08:42:35 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 08:42:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 08:42:37 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 08:42:37 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 08:42:37 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 08:42:37 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:42:38 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 08:42:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:42:38 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 08:42:39 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=402d61c6-6ce2-4f81-b97a-c528c1b97b1a HTTP/1.1" 302 0
2025-02-13 08:42:39 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 08:42:40 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:42:40 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:42:40 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:42:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:42:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f5f0f0c690>
2025-02-13 08:42:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74f6299652e0> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:42:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f5f0f0c750>
2025-02-13 08:42:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:42:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:42:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:42:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:42:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:42:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz7jxhee32trrgth0yw2arf'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bsNCjU2sSA_So67Tu5fFBHvLgYlp1AusiqqzXQSrxXQ-1739436163-1.0.1.1-o008tf0_3cn1fPs6Wb9qXpk6tXmcqxk9Wf3HtBinbtpXLfS5TTf61Z8tv5H1ubeckJ0TCFjcW7vHk4OXnpyjNA; path=/; expires=Thu, 13-Feb-25 09:12:43 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911386c28abd29f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:42:43 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:42:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz7jxhee32trrgth0yw2arf', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=bsNCjU2sSA_So67Tu5fFBHvLgYlp1AusiqqzXQSrxXQ-1739436163-1.0.1.1-o008tf0_3cn1fPs6Wb9qXpk6tXmcqxk9Wf3HtBinbtpXLfS5TTf61Z8tv5H1ubeckJ0TCFjcW7vHk4OXnpyjNA; path=/; expires=Thu, 13-Feb-25 09:12:43 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '911386c28abd29f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:42:43 - root - INFO - Inference completed in 3.30s
2025-02-13 08:42:43 - root - INFO - Tokens used - Input: 320, Output: 973, Total: 1293
2025-02-13 08:42:43 - root - INFO - Processing speed - 392.29 tokens/second
2025-02-13 08:42:43 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 4105
2025-02-13 08:42:43 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:42:43 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:42:43 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 19.649311, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:42:43.598245'}
2025-02-13 08:42:43 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 19.649311, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:42:43.598245'}
2025-02-13 08:42:43 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:42:43 - httpcore.connection - DEBUG - close.started
2025-02-13 08:42:43 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:42:43 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:42:43 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f60050d550>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"p2j8htgalt41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:42:43 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:42:43 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:42:43 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:42:43 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 4092
2025-02-13 08:42:43 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:42:43 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 973, 'total_tokens': 1293, 'model': 'llama3-70b-8192'}
2025-02-13 08:42:57 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:42:57 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'snail', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:42:57 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:42:57 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:42:57 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - - Query: snail
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:42:57 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:42:57 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:42:57 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: snail
2025-02-13 08:42:57 - tools.research.analysis_agent - INFO - Starting analysis for query: snail
2025-02-13 08:42:57 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:42:57 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:42:57 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:42:57 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:42:58 - httpcore.connection - DEBUG - close.started
2025-02-13 08:42:58 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:42:58 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:42:58 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f5f0f35bd0>
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"x1qphazsyu41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:42:58 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:42:58 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:42:58 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=snail+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 3138
2025-02-13 08:42:58 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:42:58 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06353-y HTTP/1.1" 200 112879
2025-02-13 08:42:59 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-13 08:43:00 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/ecology-and-evolution/articles/10.3389/fevo.2024.1329581/full HTTP/1.1" 200 None
2025-02-13 08:43:00 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-13 08:43:00 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S240584402409100X HTTP/1.1" 403 None
2025-02-13 08:43:00 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.earth.com:443
2025-02-13 08:43:02 - urllib3.connectionpool - DEBUG - https://www.earth.com:443 "GET /news/slugs-and-snails-prefer-los-angeles-city-life-over-rural-areas/ HTTP/1.1" 200 None
2025-02-13 08:43:02 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): parasitesandvectors.biomedcentral.com:443
2025-02-13 08:43:02 - urllib3.connectionpool - DEBUG - https://parasitesandvectors.biomedcentral.com:443 "GET /articles/10.1186/s13071-024-06298-2 HTTP/1.1" 200 97205
2025-02-13 08:43:03 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:43:03 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: snail.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:43:03 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:43:03 - httpcore.connection - DEBUG - close.started
2025-02-13 08:43:03 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:43:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:43:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f600393f50>
2025-02-13 08:43:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74f6299652e0> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:43:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f600393e10>
2025-02-13 08:43:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:43:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:43:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:43:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:43:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:43:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jkz7kkxrecms5wdd5rpkvthb'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91138751cd5580b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:43:05 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:43:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jkz7kkxrecms5wdd5rpkvthb', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91138751cd5580b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:43:05 - root - INFO - Inference completed in 2.44s
2025-02-13 08:43:05 - root - INFO - Tokens used - Input: 315, Output: 646, Total: 961
2025-02-13 08:43:05 - root - INFO - Processing speed - 393.24 tokens/second
2025-02-13 08:43:05 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3127
2025-02-13 08:43:05 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:43:05 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:43:05 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 7.786535, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:43:05.515897'}
2025-02-13 08:43:05 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 7.786535, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:43:05.515897'}
2025-02-13 08:43:05 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:43:05 - httpcore.connection - DEBUG - close.started
2025-02-13 08:43:05 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:43:05 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:43:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74f5f0f0ead0>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"16kc5h5g7g141"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 08:43:05 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:43:05 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:43:05 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:43:05 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3121
2025-02-13 08:43:05 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:43:05 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 635, 'completion_tokens': 1619, 'total_tokens': 2254, 'model': 'llama3-70b-8192'}
2025-02-13 08:46:50 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:51 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:46:51 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:51 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:46:51 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:52 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:46:52 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:52 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:52 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:46:52 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:46:52 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:46:52 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:46:52 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:46:52 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 08:46:52 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:46:52 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:46:52 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:46:52 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:46:52 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:46:52 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:46:52 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:46:52 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:46:52 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:46:52 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 08:47:29 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:47:31 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:47:31 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:47:31 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:47:31 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:47:31 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:47:31 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:47:32 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:47:32 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 08:47:32 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:47:32 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:47:32 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:47:32 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:47:32 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:47:32 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:47:32 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:47:32 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:47:32 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:47:32 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 08:48:39 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:40 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:48:40 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:40 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:48:40 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:41 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:48:41 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:41 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:41 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:48:41 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:48:41 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:41 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:48:41 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:48:41 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 08:48:47 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:48 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:48:48 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:48 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:48:48 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:48 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:48:49 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:49 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:49 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:48:49 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:48:49 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:48:49 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:48:49 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:48:49 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 08:48:49 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:48:49 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:48:49 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:48:49 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:48:49 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:48:49 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:48:49 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:48:49 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:48:49 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:48:49 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 08:54:23 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:24 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:54:24 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:24 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:54:24 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:25 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:54:25 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:25 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:25 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:54:25 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:54:25 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:54:25 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:54:25 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:54:25 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 08:54:25 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:54:25 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:54:25 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:54:25 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:54:25 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 08:54:25 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 08:54:25 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 08:54:25 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 08:54:25 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 08:54:25 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 08:54:28 - controllers.datasets_router - INFO - Attempting to list datasets in: /app/data
2025-02-13 08:54:28 - controllers.datasets_router - INFO - Found 5 datasets
2025-02-13 08:54:28 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 08:54:28 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 08:54:40 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 08:54:40 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 08:54:40 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 08:54:40 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 08:54:40 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 08:54:40 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 08:54:40 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 08:54:40 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 08:54:40 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 08:54:40 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 08:54:40 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 08:54:40 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 08:54:40 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 08:54:40 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:54:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b13d46b1190>
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 08:54:40 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:54:40 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:54:41 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 08:54:41 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 08:54:51 - tools.research.analysis_agent - WARNING - Error scraping https://www.oilfieldtechnology.com/exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/: HTTPSConnectionPool(host='www.oilfieldtechnology.com', port=443): Max retries exceeded with url: /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7b13ddbf0b50>, 'Connection to www.oilfieldtechnology.com timed out. (connect timeout=10)'))
2025-02-13 08:54:51 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 08:54:52 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 08:54:52 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 08:54:53 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 08:54:53 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 08:54:53 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 08:54:53 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 08:54:54 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 08:54:54 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 08:54:55 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 08:54:55 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=4360d5d7-5350-49da-8cdd-f006e16be0bc HTTP/1.1" 302 0
2025-02-13 08:54:56 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 08:54:56 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 08:54:56 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 08:54:56 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 08:54:56 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 08:54:56 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b13d428f110>
2025-02-13 08:54:56 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7b13fe919370> server_hostname='api.groq.com' timeout=5.0
2025-02-13 08:54:56 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b13d428f1d0>
2025-02-13 08:54:56 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:54:56 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:54:56 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:54:56 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:54:56 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 08:54:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz89cy5e0y9set21e0ht2tm'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lJ2QmBEYe_Jrgz0j7BB5XzafnFZyunIu_TZAteuLT8E-1739436899-1.0.1.1-So9l92RqEvCBXyIFUJ7RHD_QNLKvg.4RVbR3t2ubo5_oXAZKkmSZa53DvMAGCoNl0jrpkD6Xao.iNkeNXaKu2g; path=/; expires=Thu, 13-Feb-25 09:24:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'911398becd5029f5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:54:59 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 08:54:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz89cy5e0y9set21e0ht2tm', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=lJ2QmBEYe_Jrgz0j7BB5XzafnFZyunIu_TZAteuLT8E-1739436899-1.0.1.1-So9l92RqEvCBXyIFUJ7RHD_QNLKvg.4RVbR3t2ubo5_oXAZKkmSZa53DvMAGCoNl0jrpkD6Xao.iNkeNXaKu2g; path=/; expires=Thu, 13-Feb-25 09:24:59 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '911398becd5029f5-BOM', 'content-encoding': 'gzip'})
2025-02-13 08:54:59 - root - INFO - Inference completed in 2.12s
2025-02-13 08:54:59 - root - INFO - Tokens used - Input: 320, Output: 594, Total: 914
2025-02-13 08:54:59 - root - INFO - Processing speed - 431.47 tokens/second
2025-02-13 08:54:59 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3176
2025-02-13 08:54:59 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 08:54:59 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 08:54:59 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 18.988526, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:54:59.088813'}
2025-02-13 08:54:59 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 18.988526, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T08:54:59.088813'}
2025-02-13 08:54:59 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 08:54:59 - httpcore.connection - DEBUG - close.started
2025-02-13 08:54:59 - httpcore.connection - DEBUG - close.complete
2025-02-13 08:54:59 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 08:54:59 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7b13d469f910>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 08:54:59 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 08:54:59 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 08:54:59 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 08:54:59 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3170
2025-02-13 08:54:59 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 08:54:59 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 594, 'total_tokens': 914, 'model': 'llama3-70b-8192'}
2025-02-13 08:59:51 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:59:52 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:59:52 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:59:52 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 08:59:52 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 08:59:52 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:52 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 08:59:53 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 08:59:53 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 08:59:58 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:59 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 08:59:59 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:59 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 08:59:59 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 08:59:59 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 08:59:59 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:00:00 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:00:00 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 09:00:00 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 09:00:00 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:00:00 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 09:00:00 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 09:00:00 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 09:00:00 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 09:00:00 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 09:00:00 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 09:00:00 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 09:00:00 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 09:00:00 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 09:00:00 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 09:00:00 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 09:00:00 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 09:00:00 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 09:00:41 - controllers.datasets_router - INFO - Attempting to list datasets in: /app/data
2025-02-13 09:00:41 - controllers.datasets_router - INFO - Found 5 datasets
2025-02-13 09:00:42 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 09:00:42 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 09:01:05 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 09:01:05 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sargassum spp', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 09:01:05 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 09:01:05 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 09:01:05 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - - Query: Sargassum spp
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 09:01:05 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 09:01:05 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 09:01:05 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sargassum spp
2025-02-13 09:01:05 - tools.research.analysis_agent - INFO - Starting analysis for query: Sargassum spp
2025-02-13 09:01:05 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 09:01:05 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 09:01:05 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 09:01:05 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 09:01:05 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 09:01:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735ac4382c50>
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 09:01:05 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:01:05 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:01:06 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sargassum+spp+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 160
2025-02-13 09:01:06 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 09:01:06 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sargassum spp.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 09:01:06 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 09:01:06 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 09:01:06 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735ac022ed90>
2025-02-13 09:01:06 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735aeb5a92e0> server_hostname='api.groq.com' timeout=5.0
2025-02-13 09:01:06 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735ac022ee50>
2025-02-13 09:01:06 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:01:06 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:01:06 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:01:06 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:01:06 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 09:01:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5560'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.4s'), (b'x-request-id', b'req_01jkz8mnrvfvmsrg8c8r7bh9x6'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8jB9ZqTvnzkUcz9jrgB7T6nxVuCIEWeUCdaoprphud4-1739437269-1.0.1.1-fzZCoEdbG3g3KLjPm9wojurcT_R5rITPU0dvNjfEDtawWs6tbRaal1EZtUulZ4kVNxJPPxJxK9mOCxwImj9STg; path=/; expires=Thu, 13-Feb-25 09:31:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9113a1c40a3c80b5-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:01:09 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 09:01:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5560', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.4s', 'x-request-id': 'req_01jkz8mnrvfvmsrg8c8r7bh9x6', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=8jB9ZqTvnzkUcz9jrgB7T6nxVuCIEWeUCdaoprphud4-1739437269-1.0.1.1-fzZCoEdbG3g3KLjPm9wojurcT_R5rITPU0dvNjfEDtawWs6tbRaal1EZtUulZ4kVNxJPPxJxK9mOCxwImj9STg; path=/; expires=Thu, 13-Feb-25 09:31:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9113a1c40a3c80b5-BOM', 'content-encoding': 'gzip'})
2025-02-13 09:01:09 - root - INFO - Inference completed in 2.84s
2025-02-13 09:01:09 - root - INFO - Tokens used - Input: 318, Output: 691, Total: 1009
2025-02-13 09:01:09 - root - INFO - Processing speed - 355.54 tokens/second
2025-02-13 09:01:09 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3489
2025-02-13 09:01:09 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 09:01:09 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 09:01:09 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 3.826925, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T09:01:09.216777'}
2025-02-13 09:01:09 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 3.826925, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T09:01:09.216777'}
2025-02-13 09:01:09 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"k31w0fd1s33"'), (b'Content-Length', b'111'), (b'Date', b'Thu, 13 Feb 2025 09:01:09 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:01:09 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:01:09 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 09:01:09 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 3483
2025-02-13 09:01:09 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 09:01:09 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 318, 'completion_tokens': 691, 'total_tokens': 1009, 'model': 'llama3-70b-8192'}
2025-02-13 09:03:50 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 09:03:51 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 09:03:51 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 09:03:51 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 09:03:51 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 09:03:51 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:51 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 09:03:52 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 09:03:52 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-13 09:03:57 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:58 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-13 09:03:58 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:58 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-13 09:03:58 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:58 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-13 09:03:59 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:59 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:59 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-13 09:03:59 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-13 09:03:59 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-13 09:03:59 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-13 09:03:59 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-13 09:03:59 - LangfuseRunner - INFO - Logging system initialized
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-13 09:03:59 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 09:03:59 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 09:03:59 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 09:03:59 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 09:03:59 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-13 09:03:59 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-13 09:03:59 - LangfuseRunner - INFO - Configuration validation successful
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-13 09:03:59 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-13 09:03:59 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-13 09:03:59 - app - ERROR - Failed to initialize Langfuse: CreateNewEntities.__init__() missing 9 required positional arguments: 'database_url', 'organization_id', 'organization_name', 'project_id', 'project_name', 'default_user_email', 'salt', 'public_key', and 'secret_key'
2025-02-13 09:04:35 - controllers.datasets_router - INFO - Attempting to list datasets in: /app/data
2025-02-13 09:04:35 - controllers.datasets_router - INFO - Found 5 datasets
2025-02-13 09:04:35 - controllers.prompts_router - INFO - Retrieving prompts from directory: /app/prompts
2025-02-13 09:04:35 - controllers.prompts_router - INFO - Retrieved 14 prompts from 5 folders
2025-02-13 09:04:48 - controllers.analyze_data_router - INFO - === Starting new analysis request ===
2025-02-13 09:04:48 - controllers.analyze_data_router - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-13 09:04:48 - controllers.analyze_data_router - INFO - Executing analysis with tool: Analysis Agent
2025-02-13 09:04:48 - controllers.analyze_data_router - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-13 09:04:48 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - Input parameters:
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - Started generation trace
2025-02-13 09:04:48 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-13 09:04:48 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-13 09:04:48 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-13 09:04:48 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-13 09:04:48 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-13 09:04:48 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-13 09:04:48 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-13 09:04:48 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-13 09:04:48 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 09:04:48 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7340b0b5ce90>
2025-02-13 09:04:48 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:04:48 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:04:48 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:04:48 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:04:48 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:04:49 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2962
2025-02-13 09:04:49 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-13 09:04:49 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"wigxipmd5f41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 09:04:49 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 09:04:49 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:04:49 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:04:49 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:04:49 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:04:50 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15351
2025-02-13 09:04:50 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-13 09:04:51 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-13 09:04:51 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-13 09:04:52 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-13 09:04:52 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-13 09:04:52 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-13 09:04:52 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-13 09:04:53 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-13 09:04:53 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-13 09:04:53 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-13 09:04:54 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=1a4f951a-ce3d-454b-937e-133ab79efc30 HTTP/1.1" 302 0
2025-02-13 09:04:54 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-13 09:04:55 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-13 09:04:55 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-13 09:04:55 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-13 09:04:55 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-13 09:04:55 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7340b012f2d0>
2025-02-13 09:04:55 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7340daf7d250> server_hostname='api.groq.com' timeout=5.0
2025-02-13 09:04:55 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x73409244e310>
2025-02-13 09:04:55 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:04:55 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:04:55 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:04:55 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:04:55 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 13 Feb 2025 09:04:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkz8vn0he4k9d7h923yydj60'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Zn6_lcSazf5grX.FB7M5BJVG_plnKho6vjqxCO8UPtI-1739437497-1.0.1.1-DZAN889SSq4_Y_ZkTkwWaRNWAkZVp_DDsM9k6RNGFTTPAx0S6iLj181H0NISEfNvKk3p1F9uBxNVSzNM1qpe0Q; path=/; expires=Thu, 13-Feb-25 09:34:57 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9113a758ef09851f-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:04:57 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Thu, 13 Feb 2025 09:04:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkz8vn0he4k9d7h923yydj60', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Zn6_lcSazf5grX.FB7M5BJVG_plnKho6vjqxCO8UPtI-1739437497-1.0.1.1-DZAN889SSq4_Y_ZkTkwWaRNWAkZVp_DDsM9k6RNGFTTPAx0S6iLj181H0NISEfNvKk3p1F9uBxNVSzNM1qpe0Q; path=/; expires=Thu, 13-Feb-25 09:34:57 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9113a758ef09851f-BOM', 'content-encoding': 'gzip'})
2025-02-13 09:04:57 - root - INFO - Inference completed in 2.28s
2025-02-13 09:04:57 - root - INFO - Tokens used - Input: 320, Output: 621, Total: 941
2025-02-13 09:04:57 - root - INFO - Processing speed - 412.28 tokens/second
2025-02-13 09:04:57 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 2855
2025-02-13 09:04:57 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-13 09:04:57 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-13 09:04:57 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 9.042442, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T09:04:57.348901'}
2025-02-13 09:04:57 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 9.042442, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-13T09:04:57.348901'}
2025-02-13 09:04:57 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-13 09:04:57 - httpcore.connection - DEBUG - close.started
2025-02-13 09:04:57 - httpcore.connection - DEBUG - close.complete
2025-02-13 09:04:57 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-13 09:04:57 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x73409244fb10>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"9hknontoky41"'), (b'Content-Length', b'145'), (b'Date', b'Thu, 13 Feb 2025 09:04:57 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - response_closed.started
2025-02-13 09:04:57 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-13 09:04:57 - controllers.analyze_data_router - DEBUG - Analysis completed successfully, cleaning output text
2025-02-13 09:04:57 - controllers.analyze_data_router - DEBUG - Text cleaned, final length: 2850
2025-02-13 09:04:57 - controllers.analyze_data_router - INFO - Analysis request completed successfully
2025-02-13 09:04:57 - controllers.analyze_data_router - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 621, 'total_tokens': 941, 'model': 'llama3-70b-8192'}
