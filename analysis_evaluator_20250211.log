2025-02-11 09:50:12 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:14 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:50:14 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:15 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:50:15 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:15 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:50:15 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:15 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:15 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:50:15 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:50:15 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:15 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:50:16 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 09:50:22 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:23 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:50:23 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:24 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:50:24 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:24 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:50:24 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:24 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:24 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:50:24 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:50:24 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:50:24 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:50:24 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 09:50:24 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:50:24 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:50:24 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:50:24 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 09:50:24 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:50:24 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:50:24 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:50:24 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:50:24 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 09:51:32 - controllers.generate_summary_router - INFO - Received research request: query='kangaroo' tool_name='General Agent' prompt_name='scientific_research/trends.txt'
2025-02-11 09:51:32 - LangfuseRunner - INFO - === Starting tool execution: General Agent ===
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - - Query: kangaroo
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - - Dataset: None
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - - Analysis type: None
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/trends.txt
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 09:51:32 - LangfuseRunner - INFO - Executing General Agent
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - Initializing General Agent
2025-02-11 09:51:32 - LangfuseRunner - DEBUG - Invoking General Agent with query: kangaroo
2025-02-11 09:51:32 - root - INFO - Starting news search for query: kangaroo
2025-02-11 09:51:32 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 09:51:33 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 09:51:33 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75919c5f7f10>
2025-02-11 09:51:33 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7591a33b83b0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 09:51:33 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75919c5f7ed0>
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 09:51:33 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:32s'), (b'VsSaaS-Request-Id', b'329bde27-d735-45f7-b993-4230176b21bc'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 09:51:33 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 09:51:33 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=kangaroo&gl=us&hl=en&num=10 HTTP/1.1" 200 5423
2025-02-11 09:51:33 - root - INFO - Processing 10 articles for topic: kangaroo
2025-02-11 09:51:33 - root - ERROR - Error in decide_what_to_use: 'snippets'
2025-02-11 09:51:33 - root - INFO - Starting to scrape 10 news pages
2025-02-11 09:51:35 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): theonion.com:443
2025-02-11 09:51:36 - urllib3.connectionpool - DEBUG - https://theonion.com:443 "GET /kangaroo-embryo-produced-through-ivf-for-first-time/ HTTP/1.1" 200 None
2025-02-11 09:51:38 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.usatoday.com:443
2025-02-11 09:51:39 - urllib3.connectionpool - DEBUG - https://www.usatoday.com:443 "GET /videos/news/world/2025/02/10/kangaroo-embryo-produced-for-the-first-time-using-ivf/78393656007/ HTTP/1.1" 200 51266
2025-02-11 09:51:41 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cnn.com:443
2025-02-11 09:51:41 - urllib3.connectionpool - DEBUG - https://www.cnn.com:443 "GET /science/bettong-bouncing-back-brink-of-extinction-spc-c2e/index.html HTTP/1.1" 302 0
2025-02-11 09:51:41 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): edition.cnn.com:443
2025-02-11 09:51:42 - urllib3.connectionpool - DEBUG - https://edition.cnn.com:443 "GET /science/bettong-bouncing-back-brink-of-extinction-spc-c2e/index.html HTTP/1.1" 200 640184
2025-02-11 09:51:45 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.theguardian.com:443
2025-02-11 09:51:46 - urllib3.connectionpool - DEBUG - https://www.theguardian.com:443 "GET /australia-news/2025/jan/30/queensland-kangaroo-attack-willows-near-rockhampton HTTP/1.1" 200 63826
2025-02-11 09:51:48 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.npr.org:443
2025-02-11 09:51:50 - urllib3.connectionpool - DEBUG - https://www.npr.org:443 "GET /2025/01/12/nx-s1-5254719/kangaroo-species-went-extinct-in-the-pleistocene-research-hops-in-with-a-possible-explanation HTTP/1.1" 200 21500
2025-02-11 09:51:52 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bbc.com:443
2025-02-11 09:51:52 - urllib3.connectionpool - DEBUG - https://www.bbc.com:443 "GET /news/articles/cy9l1w5zlgdo HTTP/1.1" 200 40718
2025-02-11 09:51:54 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nbcnews.com:443
2025-02-11 09:51:56 - urllib3.connectionpool - DEBUG - https://www.nbcnews.com:443 "GET /news/world/kangaroo-embryo-ivf-australia-marsupials-endangered-conservation-rcna190951 HTTP/1.1" 200 None
2025-02-11 09:51:58 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.abc.net.au:443
2025-02-11 09:51:59 - urllib3.connectionpool - DEBUG - https://www.abc.net.au:443 "GET /news/2025-01-30/kangaroo-attacks-man-walking-to-his-car-at-the-gemfields-qld/104875142 HTTP/1.1" 200 None
2025-02-11 09:52:01 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cbsnews.com:443
2025-02-11 09:52:02 - urllib3.connectionpool - DEBUG - https://www.cbsnews.com:443 "GET /news/first-ivf-kangaroo-embryo-australia-scientists/ HTTP/1.1" 200 39312
2025-02-11 09:52:04 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): newatlas.com:443
2025-02-11 09:52:04 - urllib3.connectionpool - DEBUG - https://newatlas.com:443 "GET /biology/first-ivf-kangaroo-embryo/ HTTP/1.1" 200 None
2025-02-11 09:52:04 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 09:52:04 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze and summarize the following search results:\n               \n               Query: kangaroo\n               Search Results: ### Kangaroo Embryo Produced Through IVF For First Time - Satire19 hours ago\nhttps://theonion.com/kangaroo-embryo-produced-through-ivf-for-first-time/\n\n\n### Kangaroo embryo produced for the first time using IVF - 11 hours ago\nhttps://www.usatoday.com/videos/news/world/2025/02/10/kangaroo-embryo-produced-for-the-first-time-using-ivf/78393656007/\n\n\n### Australia’s bettong: It looks like a miniature kangaroo and it’s bouncing back from the brink of extinction - 3 weeks ago\nhttps://www.cnn.com/science/bettong-bouncing-back-brink-of-extinction-spc-c2e/index.html\n\n\n### Queensland man attacked by ‘massive’ kangaroo estimated to be 2m tall and weigh 100kg - 2 weeks ago\nhttps://www.theguardian.com/australia-news/2025/jan/30/queensland-kangaroo-attack-willows-near-rockhampton\n\n\n### Kangaroo species went extinct in the Pleistocene. Research hops in with a possible explanation. - 1 month ago\nhttps://www.npr.org/2025/01/12/nx-s1-5254719/kangaroo-species-went-extinct-in-the-pleistocene-research-hops-in-with-a-possible-explanation\n\n\n### Australian scientists produce first kangaroo embryo using IVF - 5 days ago\nhttps://www.bbc.com/news/articles/cy9l1w5zlgdo\n\n\n### Kangaroo embryo produced through IVF for the first time - 4 days ago\nhttps://www.nbcnews.com/news/world/kangaroo-embryo-ivf-australia-marsupials-endangered-conservation-rcna190951\n\n\n### Public warning after kangaroo attacks man outside central Queensland home - 2 weeks ago\nhttps://www.abc.net.au/news/2025-01-30/kangaroo-attacks-man-walking-to-his-car-at-the-gemfields-qld/104875142\n\n\n### First IVF kangaroo embryo claimed by Australia-based scientists. They say it's key step toward saving endangered marsupials. - 5 days ago\nhttps://www.cbsnews.com/news/first-ivf-kangaroo-embryo-australia-scientists/\n\n\n### Watch: World's first kangaroo embryo made by humans - 4 days ago\nhttps://newatlas.com/biology/first-ivf-kangaroo-embryo/\n\n               \n               Provide a comprehensive summary grouped by themes and include relevant links."}, {'role': 'user', 'content': "Summarize and group the search results based on this: 'kangaroo'. Include links, dates, and snippets from the search results."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 09:52:04 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 09:52:04 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 09:52:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75919447acd0>
2025-02-11 09:52:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7591c4319d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 09:52:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75919447a110>
2025-02-11 09:52:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 09:52:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 09:52:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 09:52:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 09:52:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 09:52:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5423'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'5.77s'), (b'x-request-id', b'req_01jkt6rjn7ebnadc9ceswhd6hy'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=L0mJwDBjog.pXCGxA5hndH2AySNpz1cd4hNyhAh6Aiw-1739267527-1.0.1.1-ULSz6zc2cIc3sBf5husKeg3s0UXtGe_z1WcUus_7bzDOJFoyMCq5llVjBBQ36StBI.g8tBcUam50.oS5Fr4.7w; path=/; expires=Tue, 11-Feb-25 10:22:07 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'910371b02d1147eb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 09:52:07 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 09:52:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5423', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '5.77s', 'x-request-id': 'req_01jkt6rjn7ebnadc9ceswhd6hy', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=L0mJwDBjog.pXCGxA5hndH2AySNpz1cd4hNyhAh6Aiw-1739267527-1.0.1.1-ULSz6zc2cIc3sBf5husKeg3s0UXtGe_z1WcUus_7bzDOJFoyMCq5llVjBBQ36StBI.g8tBcUam50.oS5Fr4.7w; path=/; expires=Tue, 11-Feb-25 10:22:07 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '910371b02d1147eb-BOM', 'content-encoding': 'gzip'})
2025-02-11 09:52:07 - root - INFO - Inference completed in 2.55s
2025-02-11 09:52:07 - root - INFO - Tokens used - Input: 612, Output: 652, Total: 1264
2025-02-11 09:52:07 - root - INFO - Processing speed - 496.22 tokens/second
2025-02-11 09:52:07 - LangfuseRunner - DEBUG - General Agent result - Content count: 10
2025-02-11 09:52:07 - LangfuseRunner - INFO - General Agent execution completed
2025-02-11 09:52:07 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 09:52:07 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 34.464888, 'success': True, 'tool': 'General Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T09:52:07.417477'}
2025-02-11 09:52:07 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 34.464888, 'success': True, 'tool': 'General Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T09:52:07.417477'}
2025-02-11 09:52:07 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 09:52:07 - httpcore.connection - DEBUG - close.started
2025-02-11 09:52:07 - httpcore.connection - DEBUG - close.complete
2025-02-11 09:52:07 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 09:52:07 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7591a33cb5d0>
2025-02-11 09:52:07 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7591a33b83b0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 09:52:07 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75919c5f6810>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 09:52:07 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:58s'), (b'VsSaaS-Request-Id', b'46fcac57-f6f9-4f2c-aa0d-114ce5e60186'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 09:52:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 09:52:07 - controllers.generate_summary_router - INFO - Research completed successfully for query: kangaroo
2025-02-11 09:52:07 - controllers.generate_summary_router - INFO - Returning response for query: kangaroo
2025-02-11 09:55:21 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:23 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:55:23 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:24 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:55:24 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:24 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:55:24 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:24 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:24 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:55:24 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:55:24 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:24 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:55:25 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 09:55:31 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:55:32 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:55:32 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:55:32 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:55:32 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:55:32 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:55:32 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:55:33 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 09:55:33 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:55:33 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:55:33 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:55:33 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:55:33 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 09:59:00 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:59:01 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:59:01 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:59:01 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:59:01 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:59:01 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:01 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:59:01 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 09:59:01 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:59:01 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:59:01 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:01 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 09:59:01 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:59:01 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:59:01 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:01 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:59:01 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 09:59:12 - research_api - INFO - Fetching available datasets
2025-02-11 09:59:12 - research_api - ERROR - Failed to retrieve datasets: name 'AnalysisAgent' is not defined
Traceback (most recent call last):
  File "/app/controllers/analyze_data_router.py", line 99, in get_datasets
    tool = AnalysisAgent(data_folder="./data")
           ^^^^^^^^^^^^^
NameError: name 'AnalysisAgent' is not defined
2025-02-11 09:59:42 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:43 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 09:59:43 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:43 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 09:59:43 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:44 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 09:59:44 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:44 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:44 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 09:59:44 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 09:59:44 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 09:59:44 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 09:59:44 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 09:59:44 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 09:59:44 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 09:59:44 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 09:59:44 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 09:59:44 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:00:01 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:10 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:00:11 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:00:11 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:00:11 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:00:11 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:00:11 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:00:11 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:00:11 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:00:11 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:00:11 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:00:11 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:00:11 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:00:11 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:00:11 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:00:11 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:00:11 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:00:11 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:00:23 - research_api - INFO - Fetching available datasets
2025-02-11 10:00:23 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 10:00:23 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 10:00:23 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 10:02:46 - research_api - INFO - === Starting new analysis request ===
2025-02-11 10:02:46 - research_api - DEBUG - Request parameters: {'query': 'Thalassia testudinum', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 10:02:46 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 10:02:46 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 10:02:46 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - - Query: Thalassia testudinum
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:02:46 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 10:02:46 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Thalassia testudinum
2025-02-11 10:02:46 - root - INFO - Starting analysis for query: Thalassia testudinum
2025-02-11 10:02:47 - root - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 10:02:47 - root - WARNING - Error in web research: name 'GoogleSerperAPIWrapper' is not defined
2025-02-11 10:02:47 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:02:47 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Thalassia testudinum.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:02:47 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:02:47 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:02:47 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x789a27952210>
2025-02-11 10:02:47 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x789a48951d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:02:47 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x789a2793ecd0>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:02:47 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x789a279e7c50>
2025-02-11 10:02:47 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x789a27968710> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:02:47 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x789a279e7c10>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:02:47 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:30s'), (b'VsSaaS-Request-Id', b'cdee8c0b-821c-409d-a74c-4c6e7d2039ed'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:02:47 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:02:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkt7c5rzf4tv1tr6gbnrft72'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jac7tAeUoPwwk6L4Zb4QgXwB_WPDEsG9y0MZXu_rWjw-1739268170-1.0.1.1-6i84kkcqUixNtB4ok5wXfCqcUX0E3dXxlxLO_M5_ghkI9qhBUKuHsmUKPGzS1QPCic3y1W1hPQz8SnhcvaH4lQ; path=/; expires=Tue, 11-Feb-25 10:32:50 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103815dcd154055-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:02:50 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:02:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkt7c5rzf4tv1tr6gbnrft72', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=jac7tAeUoPwwk6L4Zb4QgXwB_WPDEsG9y0MZXu_rWjw-1739268170-1.0.1.1-6i84kkcqUixNtB4ok5wXfCqcUX0E3dXxlxLO_M5_ghkI9qhBUKuHsmUKPGzS1QPCic3y1W1hPQz8SnhcvaH4lQ; path=/; expires=Tue, 11-Feb-25 10:32:50 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9103815dcd154055-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:02:50 - root - INFO - Inference completed in 3.04s
2025-02-11 10:02:50 - root - INFO - Tokens used - Input: 321, Output: 658, Total: 979
2025-02-11 10:02:50 - root - INFO - Processing speed - 322.41 tokens/second
2025-02-11 10:02:50 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3286
2025-02-11 10:02:50 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 10:02:50 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:02:50 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 3.095071, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:02:50.093301'}
2025-02-11 10:02:50 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 3.095071, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:02:50.093301'}
2025-02-11 10:02:50 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:02:50 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:16s'), (b'VsSaaS-Request-Id', b'ee26a369-ebfc-41ea-9902-71f40da6cb8e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:02:50 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:02:50 - research_api - ERROR - Analysis generation failed: object tuple can't be used in 'await' expression
Traceback (most recent call last):
  File "/app/controllers/analyze_data_router.py", line 53, in generate_analysis
    result, trace = await tool_runner.run_tool(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: object tuple can't be used in 'await' expression
2025-02-11 10:05:34 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:05:36 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:05:36 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:05:36 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:05:36 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:05:36 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:05:36 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:05:36 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:05:36 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:05:36 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:05:36 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:05:36 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:05:36 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:05:36 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:05:36 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:05:36 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:05:37 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:05:37 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:05:38 - research_api - INFO - Fetching available datasets
2025-02-11 10:05:38 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 10:05:38 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 10:05:38 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 10:05:54 - research_api - INFO - === Starting new analysis request ===
2025-02-11 10:05:54 - research_api - DEBUG - Request parameters: {'query': 'Thalassia testudinum', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/trends.txt', 'analysis_type': 'general'}
2025-02-11 10:05:54 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 10:05:54 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 10:05:54 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - - Query: Thalassia testudinum
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/trends.txt
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:05:54 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 10:05:54 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Thalassia testudinum
2025-02-11 10:05:54 - root - INFO - Starting analysis for query: Thalassia testudinum
2025-02-11 10:05:54 - root - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 10:05:54 - root - WARNING - Error in web research: name 'GoogleSerperAPIWrapper' is not defined
2025-02-11 10:05:54 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:05:54 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'PUBLICATION TRENDS VISUALIZATION PROMPT\n\nObjective: Generate a data-driven interpretation of publication trends for [SPECIES_NAME] based on temporal analysis\n\nRequired Data Integration:\n- Identify significant year-over-year changes in publication volume\n- Highlight peak publication periods\n- Note any notable decline periods\n- Quantify growth rates in research interest\n- Identify publication pattern cycles\n\nInterpretation Guidelines:\n- Describe temporal patterns objectively\n- Connect publication spikes to research milestones\n- Analyze research momentum across decades\n- Identify emerging or declining research themes\n- Compare recent trends to historical patterns\n\nOutput Parameters:\n- Length: 150-200 words\n- Style: Clear, analytical interpretation\n- Format: Single flowing paragraph\n- Scope: Focus on temporal patterns and their significance\n- Tone: Objective, data-focused\n\nKey Analysis Points:\n- Publication frequency changes\n- Research interest trajectories\n- Pattern significance\n- Future trend projections\n- Research field maturity indicators\n\nNote: All trend observations must be directly supported by the visualization data.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Thalassia testudinum.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:05:54 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:05:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:05:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7da1ab678650>
2025-02-11 10:05:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7da1cc57dc70> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:05:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7da1ac814b10>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:05:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7da1a405d910>
2025-02-11 10:05:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7da1ab660680> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:05:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7da1a405d8d0>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:05:54 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:7s'), (b'VsSaaS-Request-Id', b'8448bfbb-e410-4be9-afc3-ec1183158ddb'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:05:54 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:05:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5636'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'3.64s'), (b'x-request-id', b'req_01jkt7hwbhetnt06g93f5kz2ra'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m0lX8d2BGmj4xMTOdkmc7jaJvPRf.SPNPnEuV3gh3Qs-1739268356-1.0.1.1-W9Tcf8SnFn05Qzdnvxal9Jy_Q8D4V_8Lle3YhXIaVKQpSR8BR0pVrOhppzPSlf6R0Bs8w5_lFtRr5gRYFyQdhA; path=/; expires=Tue, 11-Feb-25 10:35:56 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'910385ee4e613a47-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:05:56 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:05:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5636', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '3.64s', 'x-request-id': 'req_01jkt7hwbhetnt06g93f5kz2ra', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=m0lX8d2BGmj4xMTOdkmc7jaJvPRf.SPNPnEuV3gh3Qs-1739268356-1.0.1.1-W9Tcf8SnFn05Qzdnvxal9Jy_Q8D4V_8Lle3YhXIaVKQpSR8BR0pVrOhppzPSlf6R0Bs8w5_lFtRr5gRYFyQdhA; path=/; expires=Tue, 11-Feb-25 10:35:56 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '910385ee4e613a47-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:05:56 - root - INFO - Inference completed in 2.28s
2025-02-11 10:05:56 - root - INFO - Tokens used - Input: 272, Output: 465, Total: 737
2025-02-11 10:05:56 - root - INFO - Processing speed - 322.80 tokens/second
2025-02-11 10:05:56 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 2432
2025-02-11 10:05:56 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 10:05:56 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:05:56 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 2.308926, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T10:05:56.443216'}
2025-02-11 10:05:56 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 2.308926, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T10:05:56.443216'}
2025-02-11 10:05:56 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:05:56 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:10s'), (b'VsSaaS-Request-Id', b'e8e3e0d4-a737-4ce9-a767-1aa31bcd4a5f'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:05:56 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:05:56 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 10:05:56 - research_api - DEBUG - Cleaning analysis text
2025-02-11 10:05:56 - research_api - DEBUG - Text cleaned, final length: 2427
2025-02-11 10:05:56 - research_api - INFO - Analysis request completed successfully
2025-02-11 10:05:56 - research_api - DEBUG - Response usage data: {'prompt_tokens': 272, 'completion_tokens': 465, 'total_tokens': 737, 'model': 'llama3-70b-8192'}
2025-02-11 10:06:32 - research_api - INFO - Fetching available datasets
2025-02-11 10:06:32 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 10:06:32 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 10:06:32 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 10:26:16 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:18 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:26:18 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:19 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:26:19 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:19 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:26:19 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:19 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:19 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:26:19 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:26:19 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:19 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:26:20 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 10:26:25 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:26:26 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:26:26 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:26:26 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:26:26 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:26:26 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:26:26 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:26:27 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:26:27 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:26:27 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:26:27 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:26:27 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:26:27 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:26:27 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:26:27 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:26:27 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:26:27 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:26:31 - research_api - INFO - Fetching available datasets
2025-02-11 10:26:31 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 10:26:31 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 10:26:31 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 10:30:29 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:30:30 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:30:30 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:30:30 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:30:30 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:30:30 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:30:30 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:30:30 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:30:30 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:30:30 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:30:30 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:30:30 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:30:31 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:30:31 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:30:31 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:30:31 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:30:31 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:30:31 - research_api - INFO - === Starting new analysis request ===
2025-02-11 10:30:31 - research_api - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 10:30:31 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 10:30:31 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 10:30:31 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:30:31 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 10:30:31 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-11 10:30:31 - root - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-11 10:30:31 - root - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 10:30:31 - root - WARNING - Error in web research: name 'GoogleSerperAPIWrapper' is not defined
2025-02-11 10:30:31 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:30:31 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:30:31 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:30:31 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:30:31 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd43fd50>
2025-02-11 10:30:31 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f30077c5d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:30:31 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd39e450>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:30:31 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd4519d0>
2025-02-11 10:30:31 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fe0685b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:30:31 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd451910>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:30:31 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:31s'), (b'VsSaaS-Request-Id', b'5294c5dc-7f9f-4796-aea0-317b5ad2ebac'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:30:31 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:30:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkt8yzebf16s34qd62fy6j9m'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_xT8MM3SSNOg0tQtUkTApESwCCsHHLYMWL3M8Wv..bs-1739269836-1.0.1.1-_eJyZqRTfM_oRhFtdcFhvuivlvUFG6b2H3xTX4fyzq51xkgxO1SkonPPxvx4Lt1Db77heLzx027JBu8Ht74vQA; path=/; expires=Tue, 11-Feb-25 11:00:36 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103a9fddf553a38-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:30:36 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:30:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkt8yzebf16s34qd62fy6j9m', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=_xT8MM3SSNOg0tQtUkTApESwCCsHHLYMWL3M8Wv..bs-1739269836-1.0.1.1-_eJyZqRTfM_oRhFtdcFhvuivlvUFG6b2H3xTX4fyzq51xkgxO1SkonPPxvx4Lt1Db77heLzx027JBu8Ht74vQA; path=/; expires=Tue, 11-Feb-25 11:00:36 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9103a9fddf553a38-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:30:36 - root - INFO - Inference completed in 5.31s
2025-02-11 10:30:36 - root - INFO - Tokens used - Input: 320, Output: 711, Total: 1031
2025-02-11 10:30:36 - root - INFO - Processing speed - 194.07 tokens/second
2025-02-11 10:30:36 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3251
2025-02-11 10:30:36 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 10:30:36 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:30:36 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 5.351419, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:30:36.584600'}
2025-02-11 10:30:36 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 5.351419, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:30:36.584600'}
2025-02-11 10:30:36 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:30:36 - httpcore.connection - DEBUG - close.started
2025-02-11 10:30:36 - httpcore.connection - DEBUG - close.complete
2025-02-11 10:30:36 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:30:36 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd42d890>
2025-02-11 10:30:36 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fe0685b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:30:36 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fdd42d650>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:30:36 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:2s'), (b'VsSaaS-Request-Id', b'67987772-1f62-44f3-8269-917e8a0b74ee'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:30:36 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:30:36 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 10:30:36 - research_api - DEBUG - Cleaning analysis text
2025-02-11 10:30:36 - research_api - DEBUG - Text cleaned, final length: 3246
2025-02-11 10:30:36 - research_api - INFO - Analysis request completed successfully
2025-02-11 10:30:36 - research_api - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 711, 'total_tokens': 1031, 'model': 'llama3-70b-8192'}
2025-02-11 10:44:41 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:44:42 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:44:42 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:44:42 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:44:42 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:44:42 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:44:42 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:44:43 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 10:44:43 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:44:43 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:44:43 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:44:43 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:44:43 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:44:43 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:44:43 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:44:43 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:44:43 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:44:43 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:45:03 - research_api - INFO - === Starting new analysis request ===
2025-02-11 10:45:03 - research_api - DEBUG - Request parameters: {'query': 'Acropora spp', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 10:45:03 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 10:45:03 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 10:45:03 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - - Query: Acropora spp
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:45:03 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 10:45:03 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Acropora spp
2025-02-11 10:45:03 - root - INFO - Starting analysis for query: Acropora spp
2025-02-11 10:45:03 - root - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 10:45:03 - root - WARNING - Error in web research: name 'GoogleSerperAPIWrapper' is not defined
2025-02-11 10:45:03 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:45:03 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Acropora spp.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:45:03 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:45:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:45:04 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d47a1e50>
2025-02-11 10:45:04 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x71f9fa615d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:45:04 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d3249b50>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:45:04 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d00ddd90>
2025-02-11 10:45:04 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x71f9d34fdc70> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:45:04 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d00ddd50>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:45:04 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:60s'), (b'VsSaaS-Request-Id', b'13ce971b-e23a-42f7-bc94-91b2f2031597'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:45:04 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:45:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:45:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5561'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.39s'), (b'x-request-id', b'req_01jkt9sk52eycakzgenwt9a83q'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1zVtgavuCt0nk6s6kA1ou2r7egi8gs424rp3Zq6fJj4-1739270706-1.0.1.1-n.93V.4tOsv8iPFEbJBRFbo6.6IjWsQdtSs4m64m2zGWvlGbR8y1qjqCNcqchKTwvW3_emSr5AvvhAM.np6PVQ; path=/; expires=Tue, 11-Feb-25 11:15:06 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103bf4cfb5447eb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:45:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:45:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:45:06 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:45:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:45:06 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:45:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5561', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.39s', 'x-request-id': 'req_01jkt9sk52eycakzgenwt9a83q', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=1zVtgavuCt0nk6s6kA1ou2r7egi8gs424rp3Zq6fJj4-1739270706-1.0.1.1-n.93V.4tOsv8iPFEbJBRFbo6.6IjWsQdtSs4m64m2zGWvlGbR8y1qjqCNcqchKTwvW3_emSr5AvvhAM.np6PVQ; path=/; expires=Tue, 11-Feb-25 11:15:06 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9103bf4cfb5447eb-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:45:06 - root - INFO - Inference completed in 2.92s
2025-02-11 10:45:06 - root - INFO - Tokens used - Input: 317, Output: 815, Total: 1132
2025-02-11 10:45:06 - root - INFO - Processing speed - 387.36 tokens/second
2025-02-11 10:45:06 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3664
2025-02-11 10:45:06 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 10:45:06 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:45:06 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 2.940349, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:45:06.884980'}
2025-02-11 10:45:06 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 2.940349, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:45:06.884980'}
2025-02-11 10:45:06 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:45:07 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:1s'), (b'VsSaaS-Request-Id', b'2bcc17e4-84ea-4ccc-b406-b1c4053f2416'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:45:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:45:07 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 10:45:07 - research_api - DEBUG - Cleaning analysis text
2025-02-11 10:45:07 - research_api - DEBUG - Text cleaned, final length: 3651
2025-02-11 10:45:07 - research_api - INFO - Analysis request completed successfully
2025-02-11 10:45:07 - research_api - DEBUG - Response usage data: {'prompt_tokens': 317, 'completion_tokens': 815, 'total_tokens': 1132, 'model': 'llama3-70b-8192'}
2025-02-11 10:50:12 - controllers.generate_summary_router - INFO - Received research request: query='Sclerocarya birrea' tool_name='General Agent' prompt_name='scientific_research/trends.txt'
2025-02-11 10:50:12 - LangfuseRunner - INFO - === Starting tool execution: General Agent ===
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - - Dataset: None
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - - Analysis type: None
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/trends.txt
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:50:12 - LangfuseRunner - INFO - Executing General Agent
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - Initializing General Agent
2025-02-11 10:50:12 - LangfuseRunner - DEBUG - Invoking General Agent with query: Sclerocarya birrea
2025-02-11 10:50:12 - root - INFO - Starting news search for query: Sclerocarya birrea
2025-02-11 10:50:12 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 10:50:12 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:50:12 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d00dfc50>
2025-02-11 10:50:12 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x71f9d34fc8c0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:50:12 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d00dd7d0>
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:50:12 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:56s'), (b'VsSaaS-Request-Id', b'f342f93f-e315-4d5d-988e-7dddb2e4ee8c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:50:12 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:50:13 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea&gl=us&hl=en&num=10 HTTP/1.1" 200 5504
2025-02-11 10:50:13 - root - INFO - Processing 10 articles for topic: Sclerocarya birrea
2025-02-11 10:50:13 - root - ERROR - Error in decide_what_to_use: 'snippets'
2025-02-11 10:50:13 - root - INFO - Starting to scrape 10 news pages
2025-02-11 10:50:15 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 10:50:16 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/sustainable-food-systems/articles/10.3389/fsufs.2023.1294437/full HTTP/1.1" 200 None
2025-02-11 10:50:18 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cifor-icraf.org:443
2025-02-11 10:50:22 - urllib3.connectionpool - DEBUG - https://www.cifor-icraf.org:443 "GET /knowledge/publication/26059/ HTTP/1.1" 200 30934
2025-02-11 10:50:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.goodhousekeeping.com:443
2025-02-11 10:50:25 - urllib3.connectionpool - DEBUG - https://www.goodhousekeeping.com:443 "GET /uk/beauty/skincare/a33793243/marula-oil/ HTTP/1.1" 200 None
2025-02-11 10:50:27 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.medicalnewstoday.com:443
2025-02-11 10:50:28 - urllib3.connectionpool - DEBUG - https://www.medicalnewstoday.com:443 "GET /articles/marula-oil HTTP/1.1" 200 None
2025-02-11 10:50:30 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 10:50:32 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/chemistry/articles/10.3389/fchem.2021.670530/full HTTP/1.1" 200 None
2025-02-11 10:50:34 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 10:50:34 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0378874115301963 HTTP/1.1" 302 143
2025-02-11 10:50:34 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /unsupported_browser HTTP/1.1" 400 None
2025-02-11 10:50:34 - root - ERROR - Error scraping https://www.sciencedirect.com/science/article/pii/S0378874115301963: 400 Client Error: Bad Request for url: https://www.sciencedirect.com/unsupported_browser
2025-02-11 10:50:36 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cifor-icraf.org:443
2025-02-11 10:50:40 - urllib3.connectionpool - DEBUG - https://www.cifor-icraf.org:443 "GET /knowledge/publication/27070/ HTTP/1.1" 200 30541
2025-02-11 10:50:42 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): nit.com.au:443
2025-02-11 10:50:42 - urllib3.connectionpool - DEBUG - https://nit.com.au:443 "GET /08-08-2024/12979/mangarri-man-the-mighty-marula-tree-could-flourish-in-australias-top-end HTTP/1.1" 403 None
2025-02-11 10:50:42 - root - ERROR - Error scraping https://nit.com.au/08-08-2024/12979/mangarri-man-the-mighty-marula-tree-could-flourish-in-australias-top-end: 403 Client Error: Forbidden for url: https://nit.com.au/08-08-2024/12979/mangarri-man-the-mighty-marula-tree-could-flourish-in-australias-top-end
2025-02-11 10:50:44 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): onlinelibrary.wiley.com:443
2025-02-11 10:50:45 - urllib3.connectionpool - DEBUG - https://onlinelibrary.wiley.com:443 "GET /doi/10.1155/2022/7145113 HTTP/1.1" 403 None
2025-02-11 10:50:45 - root - ERROR - Error scraping https://onlinelibrary.wiley.com/doi/10.1155/2022/7145113: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/10.1155/2022/7145113
2025-02-11 10:50:47 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.givaudan.com:443
2025-02-11 10:50:53 - urllib3.connectionpool - DEBUG - https://www.givaudan.com:443 "GET /fragrance-beauty/active-beauty/products/marula-oil HTTP/1.1" 200 None
2025-02-11 10:50:53 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:50:53 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Analyze and summarize the following search results:\n               \n               Query: Sclerocarya birrea\n               Search Results: ### The future of African wild fruits – a drive towards responsible production and consumption of the marula fruit - Jun 25, 2024\nhttps://www.frontiersin.org/journals/sustainable-food-systems/articles/10.3389/fsufs.2023.1294437/full\n\n\n### Preliminary nutritional analysis of marula (Sclerocarya birrea) fruits from two Kenyan provenances - May 22, 2024\nhttps://www.cifor-icraf.org/knowledge/publication/26059/\n\n\n### Meet the wonder oil for your skin and hair - 4 weeks ago\nhttps://www.goodhousekeeping.com/uk/beauty/skincare/a33793243/marula-oil/\n\n\n### Marula oil: Benefits, side effects, and how to use it - Apr 11, 2022\nhttps://www.medicalnewstoday.com/articles/marula-oil\n\n\n### Determination of Phenolics and Flavonoids of Some Useful Medicinal Plants and Bioassay-Guided Fractionation Substances of Sclerocarya birrea (A. Rich) Hochst Stem (Bark) Extract and Their Efficacy Against Salmonella typhi - Jun 26, 2024\nhttps://www.frontiersin.org/journals/chemistry/articles/10.3389/fchem.2021.670530/full\n\n\n### Safety and efficacy of Sclerocarya birrea (A.Rich.) Hochst (Marula) oil: A clinical perspective - Dec 24, 2015\nhttps://www.sciencedirect.com/science/article/pii/S0378874115301963\n\n\n### Ecology and biology of Uapaca kirkiana, Strychnos cocculoides and Sclerocarya birrea in Southern Africa - Aug 31, 2024\nhttps://www.cifor-icraf.org/knowledge/publication/27070/\n\n\n### Mangarri Man: the mighty marula tree could flourish in Australia's top end - Aug 8, 2024\nhttps://nit.com.au/08-08-2024/12979/mangarri-man-the-mighty-marula-tree-could-flourish-in-australias-top-end\n\n\n### Yield and Physicochemical Properties of Marula (Sclerocarya birrea) Seed Oils among Nine International Provenances Tested in Malawi - Dec 24, 2022\nhttps://onlinelibrary.wiley.com/doi/10.1155/2022/7145113\n\n\n### Marula oil - Aug 2, 2023\nhttps://www.givaudan.com/fragrance-beauty/active-beauty/products/marula-oil\n\n               \n               Provide a comprehensive summary grouped by themes and include relevant links."}, {'role': 'user', 'content': "Summarize and group the search results based on this: 'Sclerocarya birrea'. Include links, dates, and snippets from the search results."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:50:53 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:50:53 - httpcore.connection - DEBUG - close.started
2025-02-11 10:50:53 - httpcore.connection - DEBUG - close.complete
2025-02-11 10:50:53 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:50:53 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9b9c12a90>
2025-02-11 10:50:53 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x71f9fa615d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:50:53 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9b9016fd0>
2025-02-11 10:50:53 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:50:53 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:50:53 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:50:53 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:50:53 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:50:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5421'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'5.79s'), (b'x-request-id', b'req_01jkta485ef94s6tvvj4qte1ac'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103c7d37f893a38-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:50:55 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:50:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5421', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '5.79s', 'x-request-id': 'req_01jkta485ef94s6tvvj4qte1ac', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '9103c7d37f893a38-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:50:55 - root - INFO - Inference completed in 2.52s
2025-02-11 10:50:55 - root - INFO - Tokens used - Input: 657, Output: 672, Total: 1329
2025-02-11 10:50:55 - root - INFO - Processing speed - 526.42 tokens/second
2025-02-11 10:50:55 - LangfuseRunner - DEBUG - General Agent result - Content count: 10
2025-02-11 10:50:55 - LangfuseRunner - INFO - General Agent execution completed
2025-02-11 10:50:55 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:50:55 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 43.615401, 'success': True, 'tool': 'General Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T10:50:55.676438'}
2025-02-11 10:50:55 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 43.615401, 'success': True, 'tool': 'General Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T10:50:55.676438'}
2025-02-11 10:50:55 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:50:55 - httpcore.connection - DEBUG - close.started
2025-02-11 10:50:55 - httpcore.connection - DEBUG - close.complete
2025-02-11 10:50:55 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:50:55 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9d00bed90>
2025-02-11 10:50:55 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x71f9d34fc8c0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:50:55 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x71f9b9ac7a10>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:50:55 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:24s'), (b'VsSaaS-Request-Id', b'8fae29bc-db6b-4b47-a5b7-3877256613c7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:50:55 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:50:55 - controllers.generate_summary_router - INFO - Research completed successfully for query: Sclerocarya birrea
2025-02-11 10:50:55 - controllers.generate_summary_router - INFO - Returning response for query: Sclerocarya birrea
2025-02-11 10:53:58 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 10:53:59 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 10:53:59 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 10:53:59 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 10:53:59 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 10:53:59 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 10:53:59 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 10:54:00 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 10:54:00 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 10:54:00 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:54:00 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:54:00 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:54:00 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:54:00 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 10:54:00 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 10:54:00 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 10:54:00 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 10:54:00 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 10:54:06 - research_api - INFO - === Starting new analysis request ===
2025-02-11 10:54:06 - research_api - DEBUG - Request parameters: {'query': 'sea weed', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 10:54:06 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 10:54:06 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 10:54:06 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - - Query: sea weed
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 10:54:06 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 10:54:06 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 10:54:06 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea weed
2025-02-11 10:54:06 - tools.research.analysis_agent - INFO - Starting analysis for query: sea weed
2025-02-11 10:54:06 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 10:54:06 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 10:54:06 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 10:54:06 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 10:54:07 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:54:07 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e6affac90>
2025-02-11 10:54:07 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x744e6b2ddc70> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:54:07 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e6b2c9e50>
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:54:07 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:1s'), (b'VsSaaS-Request-Id', b'5770f311-852c-41f9-879a-d72956be298e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:54:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:54:07 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+weed+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2943
2025-02-11 10:54:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 10:54:08 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 303 150
2025-02-11 10:54:08 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 10:54:09 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7 HTTP/1.1" 302 0
2025-02-11 10:54:09 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-82557-7&code=64d14fca-a448-4990-913e-c5bd6ebeb4bc HTTP/1.1" 302 0
2025-02-11 10:54:10 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-82557-7 HTTP/1.1" 200 None
2025-02-11 10:54:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 10:54:11 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0960852424013531 HTTP/1.1" 403 None
2025-02-11 10:54:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-11 10:54:11 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/354281748_Characterizing_energy_flow_in_kelp_forest_food_webs_a_geochemical_review_and_call_for_additional_research HTTP/1.1" 403 None
2025-02-11 10:54:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 10:54:12 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 303 150
2025-02-11 10:54:12 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 10:54:12 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y HTTP/1.1" 302 0
2025-02-11 10:54:13 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-69362-y&code=238f1b2b-03e5-4aee-ac4e-05db11320515 HTTP/1.1" 302 0
2025-02-11 10:54:14 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-024-69362-y HTTP/1.1" 200 None
2025-02-11 10:54:14 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 10:54:14 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S1756464624003050 HTTP/1.1" 403 None
2025-02-11 10:54:14 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 10:54:14 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea weed.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 10:54:14 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 10:54:14 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 10:54:15 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e686b94d0>
2025-02-11 10:54:15 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x744e922bdd00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 10:54:15 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e517bfd10>
2025-02-11 10:54:15 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:54:15 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:54:15 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:54:15 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:54:15 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:54:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 10:54:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5562'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.38s'), (b'x-request-id', b'req_01jktaad8mf1takp09jcehpxst'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zNfAjwP_8dN6xjOuvDSUdDFNfUPR.BWglLVwVXHb5n0-1739271257-1.0.1.1-vOv6UVpXAZYlJf0O2fZbiQn2XTf6IERg2yaz5e36H.7ZPFc.yE4GNCCEasPTJqvPuVwvNbCzYYyBsFYuPeIjyA; path=/; expires=Tue, 11-Feb-25 11:24:17 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103ccc0da0847eb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 10:54:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:54:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:54:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:54:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:54:17 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 10:54:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5562', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.38s', 'x-request-id': 'req_01jktaad8mf1takp09jcehpxst', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=zNfAjwP_8dN6xjOuvDSUdDFNfUPR.BWglLVwVXHb5n0-1739271257-1.0.1.1-vOv6UVpXAZYlJf0O2fZbiQn2XTf6IERg2yaz5e36H.7ZPFc.yE4GNCCEasPTJqvPuVwvNbCzYYyBsFYuPeIjyA; path=/; expires=Tue, 11-Feb-25 11:24:17 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9103ccc0da0847eb-BOM', 'content-encoding': 'gzip'})
2025-02-11 10:54:17 - root - INFO - Inference completed in 2.82s
2025-02-11 10:54:17 - root - INFO - Tokens used - Input: 315, Output: 788, Total: 1103
2025-02-11 10:54:17 - root - INFO - Processing speed - 390.45 tokens/second
2025-02-11 10:54:17 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3775
2025-02-11 10:54:17 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 10:54:17 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 10:54:17 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.955069, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:54:17.802064'}
2025-02-11 10:54:17 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.955069, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T10:54:17.802064'}
2025-02-11 10:54:17 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 10:54:18 - httpcore.connection - DEBUG - close.started
2025-02-11 10:54:18 - httpcore.connection - DEBUG - close.complete
2025-02-11 10:54:18 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 10:54:18 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e6aff9b50>
2025-02-11 10:54:18 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x744e6b2ddc70> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 10:54:18 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x744e6aff9550>
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 10:54:18 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:46s'), (b'VsSaaS-Request-Id', b'e3446e9f-4abf-49da-a6c9-f68b9c354309'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 10:54:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 10:54:18 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 10:54:18 - research_api - DEBUG - Cleaning analysis text
2025-02-11 10:54:18 - research_api - DEBUG - Text cleaned, final length: 3765
2025-02-11 10:54:18 - research_api - INFO - Analysis request completed successfully
2025-02-11 10:54:18 - research_api - DEBUG - Response usage data: {'prompt_tokens': 315, 'completion_tokens': 788, 'total_tokens': 1103, 'model': 'llama3-70b-8192'}
2025-02-11 11:15:30 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:32 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 11:15:32 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:32 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 11:15:32 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:32 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 11:15:33 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:33 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:33 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 11:15:33 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 11:15:33 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:33 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 11:15:33 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 11:15:33 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 11:15:39 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 11:15:40 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 11:15:40 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 11:15:40 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 11:15:40 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 11:15:40 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:15:40 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 11:15:41 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 11:15:41 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 11:15:41 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 11:15:41 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 11:15:41 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:15:41 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 11:15:41 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 11:15:41 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 11:15:41 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:15:41 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 11:15:41 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 11:15:48 - research_api - INFO - Fetching available datasets
2025-02-11 11:15:48 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:15:48 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 11:15:48 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:15:48 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:15:48 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 11:15:48 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:16:10 - research_api - INFO - === Starting new analysis request ===
2025-02-11 11:16:10 - research_api - DEBUG - Request parameters: {'query': 'sea cucumber', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/trends.txt', 'analysis_type': 'general'}
2025-02-11 11:16:10 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 11:16:10 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 11:16:10 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - - Query: sea cucumber
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/trends.txt
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 11:16:10 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 11:16:10 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:16:10 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea cucumber
2025-02-11 11:16:10 - tools.research.analysis_agent - INFO - Starting analysis for query: sea cucumber
2025-02-11 11:16:10 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:16:10 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:16:10 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 11:16:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 11:16:10 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:16:10 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b320010d0>
2025-02-11 11:16:10 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x752b31e91be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:16:10 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b32f1d950>
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:16:10 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:60s'), (b'VsSaaS-Request-Id', b'2dcc8396-1d4b-44d5-98ad-7f7209350455'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:16:10 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:16:10 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+cucumber+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 3006
2025-02-11 11:16:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 11:16:11 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0048969724059485 HTTP/1.1" 403 None
2025-02-11 11:16:11 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 11:16:12 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.931903/full HTTP/1.1" 200 None
2025-02-11 11:16:12 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 11:16:13 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 303 150
2025-02-11 11:16:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 11:16:14 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0 HTTP/1.1" 302 0
2025-02-11 11:16:14 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0&code=59924b8f-3e27-4803-aa12-dad564eafb98 HTTP/1.1" 302 0
2025-02-11 11:16:19 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 200 None
2025-02-11 11:16:20 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 11:16:20 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/abs/pii/S0013935124006522 HTTP/1.1" 403 None
2025-02-11 11:16:20 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 11:16:22 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.1029147/full HTTP/1.1" 200 None
2025-02-11 11:16:22 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 11:16:22 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'PUBLICATION TRENDS VISUALIZATION PROMPT\n\nObjective: Generate a data-driven interpretation of publication trends for [SPECIES_NAME] based on temporal analysis\n\nRequired Data Integration:\n- Identify significant year-over-year changes in publication volume\n- Highlight peak publication periods\n- Note any notable decline periods\n- Quantify growth rates in research interest\n- Identify publication pattern cycles\n\nInterpretation Guidelines:\n- Describe temporal patterns objectively\n- Connect publication spikes to research milestones\n- Analyze research momentum across decades\n- Identify emerging or declining research themes\n- Compare recent trends to historical patterns\n\nOutput Parameters:\n- Length: 150-200 words\n- Style: Clear, analytical interpretation\n- Format: Single flowing paragraph\n- Scope: Focus on temporal patterns and their significance\n- Tone: Objective, data-focused\n\nKey Analysis Points:\n- Publication frequency changes\n- Research interest trajectories\n- Pattern significance\n- Future trend projections\n- Research field maturity indicators\n\nNote: All trend observations must be directly supported by the visualization data.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea cucumber.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 11:16:22 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 11:16:22 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 11:16:22 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b03fec490>
2025-02-11 11:16:22 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x752b59165d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 11:16:22 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b03fec550>
2025-02-11 11:16:22 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:16:22 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:16:22 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:16:22 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:16:22 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:16:23 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 11:16:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5638'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'3.62s'), (b'x-request-id', b'req_01jktbjxksetdtgdzwz1tkvjsb'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ielemjv_vd5.4dN87BGFu4copKSZsnFo1ZvMwiceS1M-1739272584-1.0.1.1-XRTrD_0iQjL4WACyUw5b._m6nJ32GJQK5WDWEb6grf2vVPyl2DMWOC1tIL8B5T6Fc6mLWcNpDYurjTa17k2TWA; path=/; expires=Tue, 11-Feb-25 11:46:24 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9103ed296bf64055-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 11:16:23 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:16:23 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:16:23 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:16:23 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:16:23 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 11:16:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5638', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '3.62s', 'x-request-id': 'req_01jktbjxksetdtgdzwz1tkvjsb', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Ielemjv_vd5.4dN87BGFu4copKSZsnFo1ZvMwiceS1M-1739272584-1.0.1.1-XRTrD_0iQjL4WACyUw5b._m6nJ32GJQK5WDWEb6grf2vVPyl2DMWOC1tIL8B5T6Fc6mLWcNpDYurjTa17k2TWA; path=/; expires=Tue, 11-Feb-25 11:46:24 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '9103ed296bf64055-BOM', 'content-encoding': 'gzip'})
2025-02-11 11:16:23 - root - INFO - Inference completed in 1.44s
2025-02-11 11:16:23 - root - INFO - Tokens used - Input: 266, Output: 369, Total: 635
2025-02-11 11:16:23 - root - INFO - Processing speed - 439.47 tokens/second
2025-02-11 11:16:23 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 1982
2025-02-11 11:16:23 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 11:16:24 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 11:16:24 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 13.804012, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T11:16:24.000886'}
2025-02-11 11:16:24 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 13.804012, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T11:16:24.000886'}
2025-02-11 11:16:24 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 11:16:24 - httpcore.connection - DEBUG - close.started
2025-02-11 11:16:24 - httpcore.connection - DEBUG - close.complete
2025-02-11 11:16:24 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:16:24 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b03fefa10>
2025-02-11 11:16:24 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x752b31e91be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:16:24 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x752b03feded0>
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:16:24 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:34s'), (b'VsSaaS-Request-Id', b'894efc02-9866-4567-b8a9-c806080b8a40'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:16:24 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:16:24 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 11:16:24 - research_api - DEBUG - Cleaning analysis text
2025-02-11 11:16:24 - research_api - DEBUG - Text cleaned, final length: 1978
2025-02-11 11:16:24 - research_api - INFO - Analysis request completed successfully
2025-02-11 11:16:24 - research_api - DEBUG - Response usage data: {'prompt_tokens': 266, 'completion_tokens': 369, 'total_tokens': 635, 'model': 'llama3-70b-8192'}
2025-02-11 11:17:40 - research_api - INFO - Fetching available datasets
2025-02-11 11:17:40 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:17:40 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 11:17:40 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:17:40 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:17:40 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 11:17:40 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:52:55 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:57 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 11:52:57 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:57 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 11:52:57 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:57 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 11:52:58 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:58 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:58 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 11:52:58 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 11:52:58 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:52:58 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 11:52:59 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 11:52:59 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 11:53:05 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 11:53:06 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 11:53:06 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 11:53:06 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 11:53:06 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 11:53:06 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 11:53:06 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 11:53:07 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 11:53:07 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 11:53:07 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 11:53:07 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 11:53:07 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:53:07 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 11:53:07 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 11:53:07 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 11:53:07 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 11:53:07 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 11:53:07 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 11:53:52 - research_api - INFO - Fetching available datasets
2025-02-11 11:53:52 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:53:52 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 11:53:52 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:53:52 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:53:52 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 11:53:52 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:54:07 - research_api - INFO - === Starting new analysis request ===
2025-02-11 11:54:07 - research_api - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 11:54:07 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 11:54:07 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 11:54:07 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 11:54:07 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 11:54:07 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:54:07 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-11 11:54:07 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-11 11:54:07 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:54:07 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:54:07 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:54:07 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 11:54:07 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 11:54:08 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda6870fe50>
2025-02-11 11:54:08 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda6c965b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:54:08 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda87bf92d0>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:54:08 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:1s'), (b'VsSaaS-Request-Id', b'7cb410e0-2219-4dbc-8d06-c7ce0fd3083e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:54:08 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:36s'), (b'VsSaaS-Request-Id', b'85cb9a74-c91f-4440-8dd5-3d054dbc6f8e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:54:08 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:54:08 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2961
2025-02-11 11:54:08 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-11 11:54:09 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15362
2025-02-11 11:54:09 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-11 11:54:10 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-11 11:54:10 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-11 11:54:12 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-11 11:54:12 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-11 11:54:12 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-11 11:54:12 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 11:54:13 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-11 11:54:13 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 11:54:13 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-11 11:54:14 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=8791dc4d-eb83-4fe7-97cc-3f55d36eaf76 HTTP/1.1" 302 0
2025-02-11 11:54:15 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-11 11:54:15 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 11:54:15 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 11:54:15 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 11:54:15 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 11:54:15 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda683ad990>
2025-02-11 11:54:15 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda93b59c70> server_hostname='api.groq.com' timeout=5.0
2025-02-11 11:54:15 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda6823ba90>
2025-02-11 11:54:15 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:54:15 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:54:15 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:54:15 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:54:15 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:54:17 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 11:54:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jktdr98xfwnt7twtt29vh7nv'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=J0_tUAcps1Wc1dXV9aOe9c0XNq1AEoTZkRFncRldr8Y-1739274857-1.0.1.1-doPlmrTZeU_0h8mEcrhukfH0R4Y1eyNh6WQIU2Aw9D9wHza.holXAWjDIcgqUp4BeEFLXk3fqMlj5.ELLB.Emg; path=/; expires=Tue, 11-Feb-25 12:24:17 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'910424a74cda3a38-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 11:54:17 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:54:17 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:54:17 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:54:17 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:54:17 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 11:54:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jktdr98xfwnt7twtt29vh7nv', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=J0_tUAcps1Wc1dXV9aOe9c0XNq1AEoTZkRFncRldr8Y-1739274857-1.0.1.1-doPlmrTZeU_0h8mEcrhukfH0R4Y1eyNh6WQIU2Aw9D9wHza.holXAWjDIcgqUp4BeEFLXk3fqMlj5.ELLB.Emg; path=/; expires=Tue, 11-Feb-25 12:24:17 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '910424a74cda3a38-BOM', 'content-encoding': 'gzip'})
2025-02-11 11:54:17 - root - INFO - Inference completed in 2.50s
2025-02-11 11:54:17 - root - INFO - Tokens used - Input: 320, Output: 636, Total: 956
2025-02-11 11:54:17 - root - INFO - Processing speed - 381.71 tokens/second
2025-02-11 11:54:17 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3097
2025-02-11 11:54:17 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 11:54:17 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 11:54:17 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.111195, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T11:54:17.806161'}
2025-02-11 11:54:17 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.111195, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T11:54:17.806161'}
2025-02-11 11:54:17 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 11:54:18 - httpcore.connection - DEBUG - close.started
2025-02-11 11:54:18 - httpcore.connection - DEBUG - close.complete
2025-02-11 11:54:18 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:54:18 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda6870f310>
2025-02-11 11:54:18 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda6c965b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:54:18 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda6870d990>
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:54:18 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:19s'), (b'VsSaaS-Request-Id', b'14dea9e5-29af-4a13-a02a-16a114c270c8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:54:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:54:18 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 11:54:18 - research_api - DEBUG - Cleaning analysis text
2025-02-11 11:54:18 - research_api - DEBUG - Text cleaned, final length: 3091
2025-02-11 11:54:18 - research_api - INFO - Analysis request completed successfully
2025-02-11 11:54:18 - research_api - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 636, 'total_tokens': 956, 'model': 'llama3-70b-8192'}
2025-02-11 11:59:16 - research_api - INFO - === Starting new analysis request ===
2025-02-11 11:59:16 - research_api - DEBUG - Request parameters: {'query': 'sea cucumber', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/trends.txt', 'analysis_type': 'general'}
2025-02-11 11:59:16 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 11:59:16 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 11:59:16 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - - Query: sea cucumber
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/trends.txt
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 11:59:16 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 11:59:16 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 11:59:16 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea cucumber
2025-02-11 11:59:16 - tools.research.analysis_agent - INFO - Starting analysis for query: sea cucumber
2025-02-11 11:59:16 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 11:59:16 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 11:59:16 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 11:59:16 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 11:59:16 - httpcore.connection - DEBUG - close.started
2025-02-11 11:59:16 - httpcore.connection - DEBUG - close.complete
2025-02-11 11:59:16 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:59:16 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda6c9b3d10>
2025-02-11 11:59:16 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda6c965b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:59:16 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda68729a90>
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:59:16 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:25s'), (b'VsSaaS-Request-Id', b'b2ff3b31-0df3-4d99-87d6-4ebb2ddeb897'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:59:16 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:59:17 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+cucumber+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2941
2025-02-11 11:59:17 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 11:59:17 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0048969724059485 HTTP/1.1" 403 None
2025-02-11 11:59:17 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 11:59:19 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.931903/full HTTP/1.1" 200 None
2025-02-11 11:59:19 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 11:59:21 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.1029147/full HTTP/1.1" 200 None
2025-02-11 11:59:22 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 11:59:23 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 303 150
2025-02-11 11:59:23 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 11:59:23 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0 HTTP/1.1" 302 0
2025-02-11 11:59:23 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0&code=1f2699b4-c483-4820-a1aa-0d9ca6dbeda5 HTTP/1.1" 302 0
2025-02-11 11:59:24 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 200 None
2025-02-11 11:59:24 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.fisheries.noaa.gov:443
2025-02-11 11:59:29 - urllib3.connectionpool - DEBUG - https://www.fisheries.noaa.gov:443 "GET /alaska/aquaculture/identifying-aquaculture-opportunity-areas-alaska HTTP/1.1" 200 20645
2025-02-11 11:59:29 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 11:59:29 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'PUBLICATION TRENDS VISUALIZATION PROMPT\n\nObjective: Generate a data-driven interpretation of publication trends for [SPECIES_NAME] based on temporal analysis\n\nRequired Data Integration:\n- Identify significant year-over-year changes in publication volume\n- Highlight peak publication periods\n- Note any notable decline periods\n- Quantify growth rates in research interest\n- Identify publication pattern cycles\n\nInterpretation Guidelines:\n- Describe temporal patterns objectively\n- Connect publication spikes to research milestones\n- Analyze research momentum across decades\n- Identify emerging or declining research themes\n- Compare recent trends to historical patterns\n\nOutput Parameters:\n- Length: 150-200 words\n- Style: Clear, analytical interpretation\n- Format: Single flowing paragraph\n- Scope: Focus on temporal patterns and their significance\n- Tone: Objective, data-focused\n\nKey Analysis Points:\n- Publication frequency changes\n- Research interest trajectories\n- Pattern significance\n- Future trend projections\n- Research field maturity indicators\n\nNote: All trend observations must be directly supported by the visualization data.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea cucumber.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 11:59:29 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 11:59:29 - httpcore.connection - DEBUG - close.started
2025-02-11 11:59:29 - httpcore.connection - DEBUG - close.complete
2025-02-11 11:59:29 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 11:59:29 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda4a9fbbd0>
2025-02-11 11:59:29 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda93b59c70> server_hostname='api.groq.com' timeout=5.0
2025-02-11 11:59:29 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda4a9fbc50>
2025-02-11 11:59:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:59:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:59:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:59:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:59:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 11:59:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5638'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'3.62s'), (b'x-request-id', b'req_01jkte1w9wfppv7ja3wd6w8w39'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91042c545d1547eb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:59:31 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 11:59:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5638', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '3.62s', 'x-request-id': 'req_01jkte1w9wfppv7ja3wd6w8w39', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '91042c545d1547eb-BOM', 'content-encoding': 'gzip'})
2025-02-11 11:59:31 - root - INFO - Inference completed in 1.50s
2025-02-11 11:59:31 - root - INFO - Tokens used - Input: 266, Output: 352, Total: 618
2025-02-11 11:59:31 - root - INFO - Processing speed - 410.63 tokens/second
2025-02-11 11:59:31 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 1757
2025-02-11 11:59:31 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 11:59:31 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 11:59:31 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 14.730123, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T11:59:31.248231'}
2025-02-11 11:59:31 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 14.730123, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/trends.txt', 'timestamp': '2025-02-11T11:59:31.248231'}
2025-02-11 11:59:31 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 11:59:31 - httpcore.connection - DEBUG - close.started
2025-02-11 11:59:31 - httpcore.connection - DEBUG - close.complete
2025-02-11 11:59:31 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 11:59:31 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda681b4bd0>
2025-02-11 11:59:31 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7eda6c965b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 11:59:31 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7eda68207790>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 11:59:31 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:14s'), (b'VsSaaS-Request-Id', b'b255e916-0c11-4137-80e1-75873d7716d3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 11:59:31 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 11:59:31 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 11:59:31 - research_api - DEBUG - Cleaning analysis text
2025-02-11 11:59:31 - research_api - DEBUG - Text cleaned, final length: 1754
2025-02-11 11:59:31 - research_api - INFO - Analysis request completed successfully
2025-02-11 11:59:31 - research_api - DEBUG - Response usage data: {'prompt_tokens': 586, 'completion_tokens': 988, 'total_tokens': 1574, 'model': 'llama3-70b-8192'}
2025-02-11 12:01:23 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:25 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:01:25 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:26 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:01:26 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:26 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:01:26 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:26 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:26 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:01:26 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:01:26 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:26 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:01:27 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:01:27 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 12:01:33 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:34 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:01:34 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:34 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:01:34 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:35 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:01:35 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:35 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:35 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:01:35 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:01:35 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:01:35 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:01:35 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:01:35 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 12:01:35 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:01:35 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:01:35 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:01:35 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:01:35 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:01:35 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:01:35 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:01:35 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:01:35 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:01:44 - research_api - INFO - Fetching available datasets
2025-02-11 12:01:44 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:01:44 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 12:01:44 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:01:44 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:01:44 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 12:01:44 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:01:55 - research_api - INFO - === Starting new analysis request ===
2025-02-11 12:01:55 - research_api - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 12:01:55 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 12:01:55 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 12:01:55 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 12:01:55 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 12:01:55 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:01:55 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-11 12:01:55 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-11 12:01:55 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:01:55 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:01:55 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 12:01:55 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 12:01:55 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:01:55 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765df413b8d0>
2025-02-11 12:01:55 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x765df6379be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:01:55 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765df63f0050>
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:01:56 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:50s'), (b'VsSaaS-Request-Id', b'67c03fa2-01cf-48a5-9cae-fe01428a7da3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:01:55 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:01:56 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2961
2025-02-11 12:01:56 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-11 12:01:58 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15367
2025-02-11 12:01:58 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-11 12:01:58 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-11 12:01:58 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-11 12:02:00 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-11 12:02:00 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-11 12:02:00 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-11 12:02:00 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 12:02:01 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-11 12:02:01 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 12:02:01 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-11 12:02:02 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=3d4a0b09-77e7-4604-8c1e-abba562a03d1 HTTP/1.1" 302 0
2025-02-11 12:02:02 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-11 12:02:03 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 12:02:03 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 12:02:03 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 12:02:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 12:02:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765de4bbb710>
2025-02-11 12:02:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x765e1d5e5d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 12:02:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765de4bbb7d0>
2025-02-11 12:02:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:02:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:02:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:02:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:02:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 12:02:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jkte6j6me7wvb0twxkhv45bc'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FhNskFqb2VzUru5oV4tAFWbqq5E6Kok5IyEu_WmOjyc-1739275326-1.0.1.1-Vz1FoL3WqpiLRDQ.at9yALA.jUqdrMEyksiFOCpLmeaq.szUIRDHtt6p0OO4sXjkVci5zZtBGpEe4yScNuPUfw; path=/; expires=Tue, 11-Feb-25 12:32:06 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91043013aac347eb-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:02:06 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 12:02:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jkte6j6me7wvb0twxkhv45bc', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=FhNskFqb2VzUru5oV4tAFWbqq5E6Kok5IyEu_WmOjyc-1739275326-1.0.1.1-Vz1FoL3WqpiLRDQ.at9yALA.jUqdrMEyksiFOCpLmeaq.szUIRDHtt6p0OO4sXjkVci5zZtBGpEe4yScNuPUfw; path=/; expires=Tue, 11-Feb-25 12:32:06 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91043013aac347eb-BOM', 'content-encoding': 'gzip'})
2025-02-11 12:02:06 - root - INFO - Inference completed in 2.91s
2025-02-11 12:02:06 - root - INFO - Tokens used - Input: 320, Output: 702, Total: 1022
2025-02-11 12:02:06 - root - INFO - Processing speed - 351.04 tokens/second
2025-02-11 12:02:06 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3326
2025-02-11 12:02:06 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 12:02:06 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 12:02:06 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 10.811172, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:02:06.285283'}
2025-02-11 12:02:06 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 10.811172, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:02:06.285283'}
2025-02-11 12:02:06 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 12:02:06 - httpcore.connection - DEBUG - close.started
2025-02-11 12:02:06 - httpcore.connection - DEBUG - close.complete
2025-02-11 12:02:06 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:02:06 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765de4bd0090>
2025-02-11 12:02:06 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x765df6379be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:02:06 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x765df40c30d0>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:02:06 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:36s'), (b'VsSaaS-Request-Id', b'7073ccd8-5b58-47c8-bcd6-d251b2331b1b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:02:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:02:06 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 12:02:06 - research_api - DEBUG - Cleaning analysis text
2025-02-11 12:02:06 - research_api - DEBUG - Text cleaned, final length: 3319
2025-02-11 12:02:06 - research_api - INFO - Analysis request completed successfully
2025-02-11 12:02:06 - research_api - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 702, 'total_tokens': 1022, 'model': 'llama3-70b-8192'}
2025-02-11 12:02:27 - research_api - INFO - Fetching available datasets
2025-02-11 12:02:27 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:02:27 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 12:02:27 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:02:27 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:02:27 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 12:02:27 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:08:50 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:08:52 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:08:52 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:08:52 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:08:52 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:08:52 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:08:52 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:08:53 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:08:53 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 12:08:59 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:09:00 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:09:00 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:09:00 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:09:00 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:09:00 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:09:00 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:09:01 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:09:01 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 12:09:01 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:09:01 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:09:01 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:09:01 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:09:01 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:09:01 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:09:01 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:09:01 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:09:01 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:10:22 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:24 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:10:24 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:24 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:10:24 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:24 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:10:24 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:24 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:24 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:10:24 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:10:25 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:25 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:10:25 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:10:25 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 12:10:31 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:10:32 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:10:32 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:10:32 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:10:32 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:10:32 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:10:32 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:10:33 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:10:33 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 12:10:33 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:10:33 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:10:33 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:10:33 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:10:33 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:10:33 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:10:33 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:10:33 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:10:33 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:10:43 - research_api - INFO - Fetching available datasets
2025-02-11 12:10:43 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:10:43 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 12:10:43 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:10:43 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:10:43 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 12:10:43 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:12:17 - research_api - INFO - === Starting new analysis request ===
2025-02-11 12:12:17 - research_api - DEBUG - Request parameters: {'query': 'Sclerocarya birrea', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 12:12:17 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 12:12:17 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 12:12:17 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - - Query: Sclerocarya birrea
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 12:12:17 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 12:12:17 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:12:17 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Sclerocarya birrea
2025-02-11 12:12:17 - tools.research.analysis_agent - INFO - Starting analysis for query: Sclerocarya birrea
2025-02-11 12:12:17 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:12:17 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:12:17 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 12:12:17 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 12:12:18 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:12:18 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c60422690>
2025-02-11 12:12:18 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a3c62675b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:12:18 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c603be750>
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:12:18 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:24s'), (b'VsSaaS-Request-Id', b'99a6bf03-8c8d-4bb1-a8c0-02e7246ce981'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:12:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:12:18 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Sclerocarya+birrea+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 2961
2025-02-11 12:12:18 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.oilfieldtechnology.com:443
2025-02-11 12:12:19 - urllib3.connectionpool - DEBUG - https://www.oilfieldtechnology.com:443 "GET /exploration/10022025/impact-oil-gas-announces-spudding-of-marula-1x-exploration-block-2913-offshore-namibia/ HTTP/1.1" 200 15363
2025-02-11 12:12:19 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oilreviewafrica.com:443
2025-02-11 12:12:20 - urllib3.connectionpool - DEBUG - https://oilreviewafrica.com:443 "GET /exploration/exploration/tamboti-1x-highlights-namibia-s-deep-offshore-potential-for-impact-oil-gas HTTP/1.1" 200 None
2025-02-11 12:12:20 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mongabay.com:443
2025-02-11 12:12:21 - urllib3.connectionpool - DEBUG - https://news.mongabay.com:443 "GET /2024/06/explorer-elephants-in-transfrontier-conservation-area-offer-solution-to-tree-damage/ HTTP/1.1" 200 None
2025-02-11 12:12:21 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.researchgate.net:443
2025-02-11 12:12:21 - urllib3.connectionpool - DEBUG - https://www.researchgate.net:443 "GET /publication/342237547_Vegetation_Classification_and_Habitat_Types_of_Gambella_National_Park HTTP/1.1" 403 None
2025-02-11 12:12:21 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 12:12:22 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 303 150
2025-02-11 12:12:22 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 12:12:23 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9 HTTP/1.1" 302 0
2025-02-11 12:12:23 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-023-34550-9&code=1f2cf0d2-4cfb-4b13-bcfa-7288755964a1 HTTP/1.1" 302 0
2025-02-11 12:12:24 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41598-023-34550-9 HTTP/1.1" 200 None
2025-02-11 12:12:24 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 12:12:24 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Sclerocarya birrea.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 12:12:24 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 12:12:24 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 12:12:24 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c600b9ed0>
2025-02-11 12:12:24 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a3c898a1c70> server_hostname='api.groq.com' timeout=5.0
2025-02-11 12:12:24 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c50eab950>
2025-02-11 12:12:24 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:12:24 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:12:24 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:12:24 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:12:24 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:12:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 12:12:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jktesgt6e67bq6mbg8va9n99'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Fpg33Of2nWrx8TonmBrRfoKuE8f05C_IcFQLT4a3mRk-1739275947-1.0.1.1-J05OosF3l.mg1FhsS5mzd2o9NzOEXa6m93SkavDFq0BHrx6gFRXzqNOkaIS8YsjyUji06jkGiwdQqpSGqhx5_w; path=/; expires=Tue, 11-Feb-25 12:42:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91043f3dfa073a38-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 12:12:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:12:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:12:26 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:12:26 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:12:26 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 12:12:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jktesgt6e67bq6mbg8va9n99', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Fpg33Of2nWrx8TonmBrRfoKuE8f05C_IcFQLT4a3mRk-1739275947-1.0.1.1-J05OosF3l.mg1FhsS5mzd2o9NzOEXa6m93SkavDFq0BHrx6gFRXzqNOkaIS8YsjyUji06jkGiwdQqpSGqhx5_w; path=/; expires=Tue, 11-Feb-25 12:42:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91043f3dfa073a38-BOM', 'content-encoding': 'gzip'})
2025-02-11 12:12:26 - root - INFO - Inference completed in 2.59s
2025-02-11 12:12:26 - root - INFO - Tokens used - Input: 320, Output: 700, Total: 1020
2025-02-11 12:12:26 - root - INFO - Processing speed - 393.60 tokens/second
2025-02-11 12:12:26 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3336
2025-02-11 12:12:26 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 12:12:26 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 12:12:26 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 9.175114, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:12:26.997578'}
2025-02-11 12:12:26 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 9.175114, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:12:26.997578'}
2025-02-11 12:12:26 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 12:12:27 - httpcore.connection - DEBUG - close.started
2025-02-11 12:12:27 - httpcore.connection - DEBUG - close.complete
2025-02-11 12:12:27 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:12:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c603be690>
2025-02-11 12:12:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a3c62675b50> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:12:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a3c626c1490>
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:12:27 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1498'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:15s'), (b'VsSaaS-Request-Id', b'e9475484-b754-470a-94ed-61dde4770746'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:12:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:12:27 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 12:12:27 - research_api - DEBUG - Cleaning analysis text
2025-02-11 12:12:27 - research_api - DEBUG - Text cleaned, final length: 3330
2025-02-11 12:12:27 - research_api - INFO - Analysis request completed successfully
2025-02-11 12:12:27 - research_api - DEBUG - Response usage data: {'prompt_tokens': 320, 'completion_tokens': 700, 'total_tokens': 1020, 'model': 'llama3-70b-8192'}
2025-02-11 12:17:05 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:08 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:17:08 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:08 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:17:08 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:08 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:17:08 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:09 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:09 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:17:09 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:17:09 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:09 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:17:10 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:17:10 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 12:17:16 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:17:17 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:17:17 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:17:17 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:17:17 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:17:17 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:17:17 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:17:18 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:17:18 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 12:17:18 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:17:18 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:17:18 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:17:18 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:17:18 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:17:18 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Configuration loaded - Host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:17:18 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Using custom host: https://fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev
2025-02-11 12:17:18 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:17:18 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:17:24 - research_api - INFO - Fetching available datasets
2025-02-11 12:17:24 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:17:24 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 12:17:24 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:17:24 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:17:24 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 12:17:24 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:23:25 - research_api - INFO - === Starting new analysis request ===
2025-02-11 12:23:25 - research_api - DEBUG - Request parameters: {'query': 'sea cucumber', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 12:23:25 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 12:23:25 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 12:23:25 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - - Query: sea cucumber
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 12:23:25 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 12:23:25 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:23:25 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: sea cucumber
2025-02-11 12:23:25 - tools.research.analysis_agent - INFO - Starting analysis for query: sea cucumber
2025-02-11 12:23:25 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:23:25 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:23:25 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 12:23:25 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 12:23:25 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:23:25 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acc83df090>
2025-02-11 12:23:25 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x77acca691be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:23:25 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acca6e7cd0>
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:23:25 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:49s'), (b'VsSaaS-Request-Id', b'afcb3a2d-a998-4f05-8973-5201113de368'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:23:25 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:23:26 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=sea+cucumber+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 3006
2025-02-11 12:23:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 12:23:26 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/pii/S0048969724059485 HTTP/1.1" 403 None
2025-02-11 12:23:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 12:23:29 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.931903/full HTTP/1.1" 200 None
2025-02-11 12:23:29 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.nature.com:443
2025-02-11 12:23:30 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 303 150
2025-02-11 12:23:30 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.nature.com:443
2025-02-11 12:23:31 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0 HTTP/1.1" 302 0
2025-02-11 12:23:31 - urllib3.connectionpool - DEBUG - https://idp.nature.com:443 "GET /transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-024-45730-0&code=18d1512d-6bc8-4da1-8bdd-5768d26143e1 HTTP/1.1" 302 0
2025-02-11 12:23:32 - urllib3.connectionpool - DEBUG - https://www.nature.com:443 "GET /articles/s41467-024-45730-0 HTTP/1.1" 200 None
2025-02-11 12:23:32 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.sciencedirect.com:443
2025-02-11 12:23:33 - urllib3.connectionpool - DEBUG - https://www.sciencedirect.com:443 "GET /science/article/abs/pii/S0013935124006522 HTTP/1.1" 403 None
2025-02-11 12:23:33 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.frontiersin.org:443
2025-02-11 12:23:34 - urllib3.connectionpool - DEBUG - https://www.frontiersin.org:443 "GET /journals/marine-science/articles/10.3389/fmars.2022.1029147/full HTTP/1.1" 200 None
2025-02-11 12:23:34 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 12:23:34 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: sea cucumber.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 12:23:34 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 12:23:34 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 12:23:34 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acb88f0310>
2025-02-11 12:23:34 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x77acf19d9d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 12:23:34 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acb88f03d0>
2025-02-11 12:23:34 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:23:34 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:23:34 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:23:34 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:23:34 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 12:23:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5561'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.39s'), (b'x-request-id', b'req_01jktfdz5ce458c8h26pb3dynd'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Z6cVZaKRVlLHHOWqgSYVSxLiwaSUUhZcEmU.NabJJcQ-1739276617-1.0.1.1-kavt7ln1GAouOCamvnnWVW3Zh0HLU_9FFF5fnnACZTmMIwPpYu8EBK_yEdI4a5DEptXVJG7YwR.M4lB6gWB6lg; path=/; expires=Tue, 11-Feb-25 12:53:37 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91044f99dbe13a38-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:23:37 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 12:23:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5561', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.39s', 'x-request-id': 'req_01jktfdz5ce458c8h26pb3dynd', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Z6cVZaKRVlLHHOWqgSYVSxLiwaSUUhZcEmU.NabJJcQ-1739276617-1.0.1.1-kavt7ln1GAouOCamvnnWVW3Zh0HLU_9FFF5fnnACZTmMIwPpYu8EBK_yEdI4a5DEptXVJG7YwR.M4lB6gWB6lg; path=/; expires=Tue, 11-Feb-25 12:53:37 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91044f99dbe13a38-BOM', 'content-encoding': 'gzip'})
2025-02-11 12:23:37 - root - INFO - Inference completed in 2.84s
2025-02-11 12:23:37 - root - INFO - Tokens used - Input: 315, Output: 808, Total: 1123
2025-02-11 12:23:37 - root - INFO - Processing speed - 394.82 tokens/second
2025-02-11 12:23:37 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 3742
2025-02-11 12:23:37 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 12:23:37 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 12:23:37 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 11.897945, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:23:37.431625'}
2025-02-11 12:23:37 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 11.897945, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:23:37.431625'}
2025-02-11 12:23:37 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 12:23:37 - httpcore.connection - DEBUG - close.started
2025-02-11 12:23:37 - httpcore.connection - DEBUG - close.complete
2025-02-11 12:23:37 - httpcore.connection - DEBUG - connect_tcp.started host='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' port=443 local_address=None timeout=20 socket_options=None
2025-02-11 12:23:37 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acb88d7d50>
2025-02-11 12:23:37 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x77acca691be0> server_hostname='fantastic-waddle-694pv64vjwqv244jp-3000.app.github.dev' timeout=20
2025-02-11 12:23:37 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x77acb88d6d50>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 11 Feb 2025 12:23:37 GMT'), (b'Content-Length', b'0'), (b'Connection', b'keep-alive'), (b'WWW-Authenticate', b'tunnel'), (b'X-Content-Type-Options', b'nosniff'), (b'RateLimit-Limit', b'HttpRequestRatePerPort:1500/m'), (b'RateLimit-Remaining', b'HttpRequestRatePerPort:1499'), (b'RateLimit-Reset', b'HttpRequestRatePerPort:3s'), (b'VsSaaS-Request-Id', b'1be60385-64c0-46c4-a63b-486ee8cc4a5c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains'), (b'X-Served-By', b'tunnels-prod-rel-inc1-v3-cluster')])
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:23:37 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:23:37 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 12:23:37 - research_api - DEBUG - Cleaning analysis text
2025-02-11 12:23:37 - research_api - DEBUG - Text cleaned, final length: 3734
2025-02-11 12:23:37 - research_api - INFO - Analysis request completed successfully
2025-02-11 12:23:37 - research_api - DEBUG - Response usage data: {'prompt_tokens': 315, 'completion_tokens': 808, 'total_tokens': 1123, 'model': 'llama3-70b-8192'}
2025-02-11 12:32:35 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:37 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:32:37 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:37 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:32:37 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:38 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:32:38 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:38 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:38 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:32:38 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:32:38 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:38 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:32:38 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:32:39 - __main__ - INFO - INIT_DB is true. Running database initialization.
2025-02-11 12:32:46 - utils.evaluation - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.evaluation - INFO - Initialized FactualAccuracyEvaluator
2025-02-11 12:32:47 - utils.source_coverage - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.source_coverage - INFO - Initialized SourceCoverageEvaluator
2025-02-11 12:32:47 - utils.logical_coherence - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.logical_coherence - INFO - Initialized LogicalCoherenceEvaluator
2025-02-11 12:32:47 - relevance_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.automated_tests - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.automated_tests - INFO - Initialized AutomatedTestEvaluator
2025-02-11 12:32:47 - utils.analysis_evaluator - INFO - Creating new AnalysisEvaluator instance
2025-02-11 12:32:47 - utils.analysis_evaluator - ERROR - Failed to initialize Langfuse: 'Langfuse' object is not callable
2025-02-11 12:32:47 - utils.analysis_evaluator - INFO - Initializing AnalysisEvaluator
2025-02-11 12:32:48 - research_agent.research_agent - INFO - Successfully imported GoogleSerperAPIWrapper
2025-02-11 12:32:48 - LangfuseRunner - INFO - Logging system initialized
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Debug logging enabled
2025-02-11 12:32:48 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:32:48 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:32:48 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-11 12:32:48 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:32:48 - LangfuseRunner - INFO - Creating new LangfuseRunner instance
2025-02-11 12:32:48 - LangfuseRunner - INFO - === Initializing LangfuseRunner ===
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Configuration loaded - Host: http://langfuse-server:3000
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Public Key present: Yes
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Secret Key present: Yes
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Starting configuration validation
2025-02-11 12:32:48 - LangfuseRunner - INFO - Configuration validation successful
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Using custom host: http://langfuse-server:3000
2025-02-11 12:32:48 - LangfuseRunner - INFO - Successfully initialized Langfuse client
2025-02-11 12:32:48 - LangfuseRunner - DEBUG - Model costs configured: {'default': 0.001}
2025-02-11 12:32:57 - research_api - INFO - Fetching available datasets
2025-02-11 12:32:57 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:32:57 - research_api - DEBUG - AnalysisAgent initialized
2025-02-11 12:32:57 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:32:57 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:32:57 - research_api - INFO - Successfully retrieved 5 datasets
2025-02-11 12:32:57 - research_api - DEBUG - Available datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:33:26 - research_api - INFO - === Starting new analysis request ===
2025-02-11 12:33:26 - research_api - DEBUG - Request parameters: {'query': 'Thalassia testudinum', 'tool_name': 'Analysis Agent', 'dataset': 'lit_fos.csv', 'prompt_name': 'scientific_research/fields.txt', 'analysis_type': 'general'}
2025-02-11 12:33:26 - research_api - INFO - Executing analysis with tool: Analysis Agent
2025-02-11 12:33:26 - research_api - DEBUG - Analysis parameters - Dataset: lit_fos.csv, Type: general
2025-02-11 12:33:26 - LangfuseRunner - INFO - === Starting tool execution: Analysis Agent ===
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - Input parameters:
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - - Query: Thalassia testudinum
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - - Dataset: lit_fos.csv
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - - Analysis type: general
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - - Prompt name: scientific_research/fields.txt
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - Langfuse trace created successfully
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - Started generation trace
2025-02-11 12:33:26 - LangfuseRunner - INFO - Executing Analysis Agent
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - Initializing Analysis Agent
2025-02-11 12:33:26 - tools.research.analysis_agent - INFO - SERPER_API_KEY present: True
2025-02-11 12:33:26 - LangfuseRunner - DEBUG - Invoking Analysis Agent - Dataset: lit_fos.csv, Query: Thalassia testudinum
2025-02-11 12:33:26 - tools.research.analysis_agent - INFO - Starting analysis for query: Thalassia testudinum
2025-02-11 12:33:26 - tools.research.analysis_agent - INFO - Looking for datasets in: /app/data
2025-02-11 12:33:26 - tools.research.analysis_agent - INFO - Found datasets: ['pat_app.csv', 'pat_fos.csv', 'literature_trends.csv', 'lit_fos.csv', 'lit_aff.csv']
2025-02-11 12:33:26 - tools.research.analysis_agent - INFO - Data validation results: {'missing_data': {'fields_of_study': 0, 'n': 0}, 'datatypes': {'fields_of_study': dtype('O'), 'n': dtype('int64')}, 'row_count': 20, 'column_count': 2}
2025-02-11 12:33:26 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): google.serper.dev:443
2025-02-11 12:33:26 - httpcore.connection - DEBUG - connect_tcp.started host='langfuse-server' port=3000 local_address=None timeout=20 socket_options=None
2025-02-11 12:33:26 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7d6c4c5ec990>
2025-02-11 12:33:26 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:33:26 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:33:26 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:33:26 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:33:26 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"11moppqblxc41"'), (b'Content-Length', b'145'), (b'Date', b'Tue, 11 Feb 2025 12:33:27 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:33:27 - urllib3.connectionpool - DEBUG - https://google.serper.dev:443 "POST /news?q=Thalassia+testudinum+fields_of_study+n+analysis+research&gl=us&hl=en&num=5 HTTP/1.1" 200 167
2025-02-11 12:33:27 - root - INFO - Start inference with model llama3-70b-8192 on host groq
2025-02-11 12:33:27 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'DATA-DRIVEN RESEARCH SYNTHESIS PROMPT\n\nObjective: Generate a data-integrated research overview for [SPECIES_NAME] that directly incorporates provided dataset metrics\n\nRequired Data Integration:\n- Extract and cite specific numerical values from the dataset\n- Reference exact measurements and statistics when available\n- Use quantitative trends to support qualitative statements\n- Incorporate statistical patterns from the provided data\n- Connect data points to broader research themes\n\nStructure Guidelines:\n- Begin with most statistically significant findings from the data\n- Flow naturally between data-supported topics\n- Avoid generic literature review statements without data backing\n- Integrate numerical evidence throughout the narrative\n- Reference specific metrics while maintaining readability\n- Exclude methodology descriptions and data source references\n\nOutput Parameters:\n- Length: 400-600 words\n- Style: Professional, authoritative research summary\n- Format: Flowing paragraphs without numbering or subsections\n- Variables: Use [SPECIES_NAME] consistently\n- Tone: Data-driven but accessible\n\nFocus Areas:\n- Research trends supported by dataset metrics\n- Quantified research impacts and outcomes\n- Measured ecological and biological parameters\n- Statistical evidence of significance\n- Data-verified future research directions\n\nNote: Every major claim should be supported by at least one specific data point from the provided dataset.'}, {'role': 'user', 'content': "Analyze the dataset 'lit_fos.csv' in the context of the query: Thalassia testudinum.\n                            Include relevant insights from web research where applicable.\n                            Focus on connecting statistical findings with broader industry/research context."}], 'model': 'llama3-70b-8192', 'temperature': 0.7}}
2025-02-11 12:33:27 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-02-11 12:33:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-11 12:33:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7d6c4934db10>
2025-02-11 12:33:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7d6c73821d00> server_hostname='api.groq.com' timeout=5.0
2025-02-11 12:33:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7d6c4c5f4450>
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:33:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 11 Feb 2025 12:33:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'us-west-1'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5559'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.41s'), (b'x-request-id', b'req_01jktg02anefystqf0vtpxnqhh'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=":443"; ma=86400'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uS.2brBR6M43FqZUrTae8m5y9c1MZpeow6e1Ke5Pke8-1739277209-1.0.1.1-BD6efEWQBvFVqtUoYgpdbbugSWviIy7UJ79gX087W3tI13tp11ZJWGyZFEc_iP9Lv9pazKvsHKZ1s_LsLoidHg; path=/; expires=Tue, 11-Feb-25 13:03:29 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91045e147fab47ca-BOM'), (b'Content-Encoding', b'gzip')])
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:33:29 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 11 Feb 2025 12:33:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'us-west-1', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5559', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '4.41s', 'x-request-id': 'req_01jktg02anefystqf0vtpxnqhh', 'via': '1.1 google', 'alt-svc': 'h3=":443"; ma=86400', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=uS.2brBR6M43FqZUrTae8m5y9c1MZpeow6e1Ke5Pke8-1739277209-1.0.1.1-BD6efEWQBvFVqtUoYgpdbbugSWviIy7UJ79gX087W3tI13tp11ZJWGyZFEc_iP9Lv9pazKvsHKZ1s_LsLoidHg; path=/; expires=Tue, 11-Feb-25 13:03:29 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '91045e147fab47ca-BOM', 'content-encoding': 'gzip'})
2025-02-11 12:33:29 - root - INFO - Inference completed in 2.26s
2025-02-11 12:33:29 - root - INFO - Tokens used - Input: 321, Output: 583, Total: 904
2025-02-11 12:33:29 - root - INFO - Processing speed - 399.94 tokens/second
2025-02-11 12:33:29 - LangfuseRunner - DEBUG - Analysis Agent result - Analysis length: 2667
2025-02-11 12:33:29 - LangfuseRunner - INFO - Analysis Agent execution completed
2025-02-11 12:33:29 - LangfuseRunner - INFO - Tool execution completed successfully
2025-02-11 12:33:29 - LangfuseRunner - DEBUG - Prepared trace data: {'duration': 3.259586, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:33:29.771846'}
2025-02-11 12:33:29 - LangfuseRunner - DEBUG - Trace data prepared: {'duration': 3.259586, 'success': True, 'tool': 'Analysis Agent', 'prompt_used': 'scientific_research/fields.txt', 'timestamp': '2025-02-11T12:33:29.771846'}
2025-02-11 12:33:29 - LangfuseRunner - DEBUG - Flushing Langfuse traces
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 207, b'Multi-Status', [(b'X-Content-Type-Options', b'nosniff'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Permissions-Policy', b'autoplay=*, fullscreen=*, microphone=*'), (b'x-frame-options', b'SAMEORIGIN'), (b'Vary', b'Origin, Accept-Encoding'), (b'Content-Type', b'application/json; charset=utf-8'), (b'ETag', b'"h5rwjs62eq41"'), (b'Content-Length', b'145'), (b'Date', b'Tue, 11 Feb 2025 12:33:29 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - response_closed.started
2025-02-11 12:33:29 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-11 12:33:29 - research_api - DEBUG - Analysis completed successfully, cleaning output text
2025-02-11 12:33:29 - research_api - DEBUG - Cleaning analysis text
2025-02-11 12:33:29 - research_api - DEBUG - Text cleaned, final length: 2662
2025-02-11 12:33:29 - research_api - INFO - Analysis request completed successfully
2025-02-11 12:33:29 - research_api - DEBUG - Response usage data: {'prompt_tokens': 321, 'completion_tokens': 583, 'total_tokens': 904, 'model': 'llama3-70b-8192'}
